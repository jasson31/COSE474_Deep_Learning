{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "#import d2l\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy\n",
    "import yacht_main as yacht\n",
    "import copy\n",
    "import collections\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import IPython as ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Reshape()\n",
       "  (1): Linear(in_features=5, out_features=50, bias=True)\n",
       "  (2): LeakyReLU(negative_slope=0.01)\n",
       "  (3): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (4): LeakyReLU(negative_slope=0.01)\n",
       "  (5): Linear(in_features=30, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SIZE = 5\n",
    "OUTPUT_SIZE = 12\n",
    "\n",
    "class Reshape(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(INPUT_SIZE)\n",
    "    \n",
    "net = torch.nn.Sequential(\n",
    "    Reshape(),\n",
    "    \n",
    "    nn.Linear(in_features=INPUT_SIZE, out_features=50),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(50,30),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(30,OUTPUT_SIZE)\n",
    "    \n",
    "    #nn.Linear(in_features=INPUT_SIZE, out_features = OUTPUT_SIZE)\n",
    ")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.uniform_(m.weight,-0.1,0.1)\n",
    "\n",
    "net = net.float()\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def try_gpu():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "device = try_gpu()\n",
    "print(torch.cuda.is_available())\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data = []\n",
    "SCALE = 30.0\n",
    "\n",
    "\n",
    "def pack(org):\n",
    "    return (org/SCALE)\n",
    "\n",
    "def unpack(norm):\n",
    "    return round(SCALE*float(norm))\n",
    "\n",
    "for d1 in range(6):\n",
    "    for d2 in range(6):\n",
    "        for d3 in range(6):\n",
    "            for d4 in range(6):\n",
    "                for d5 in range(6):\n",
    "                    dices = [d1+1,d2+1,d3+1,d4+1,d5+1]\n",
    "                    scores = [pack(f(dices)) for f in yacht.score_func]\n",
    "                    #scores = [yacht.score_func[6](dices)/SCALE]\n",
    "                    \n",
    "                    dt = torch.tensor([dices.count(i+1) for i in range(6)], dtype = torch.float32, requires_grad = False)\n",
    "                    st = torch.tensor(scores, dtype = torch.float32, requires_grad = False)\n",
    "                    \n",
    "                    train_data.append((dt,st))\n",
    "\n",
    "print(str(len(train_data)))\n",
    "\n",
    "for x,y in train_data:\n",
    "    cont = \"\"\n",
    "    for a in x:\n",
    "        cont += str(int(a))+\" \"\n",
    "    cont += \" | \"\n",
    "    for b in y:\n",
    "        cont += str(unpack(b))+\" \"\n",
    "    print(cont)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): D_Reshape()\n",
       "  (1): Linear(in_features=13, out_features=300, bias=True)\n",
       "  (2): LeakyReLU(negative_slope=0.01)\n",
       "  (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (4): LeakyReLU(negative_slope=0.01)\n",
       "  (5): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (6): LeakyReLU(negative_slope=0.01)\n",
       "  (7): Linear(in_features=50, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "MEMORY_SIZE = 10000\n",
    "GAMMA = 0.7\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 500\n",
    "TARGET_UPDATE = 10\n",
    "SCALE = 30.0\n",
    "#ALPHA = 0.1\n",
    "\n",
    "D_INPUT_SIZE = 13\n",
    "D_OUTPUT_SIZE = 12\n",
    "\n",
    "class D_Reshape(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(D_INPUT_SIZE)\n",
    "\n",
    "policy_net = torch.nn.Sequential(\n",
    "    D_Reshape(),\n",
    "    nn.Linear(in_features=D_INPUT_SIZE, out_features=300),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(300,100),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(100,50),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(50,OUTPUT_SIZE)\n",
    ")\n",
    "\n",
    "policy_net.apply(init_weights)\n",
    "target_net = copy.deepcopy(policy_net)\n",
    "target_net.eval()\n",
    "\n",
    "policy_net.to(device)\n",
    "target_net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = collections.namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"transition 저장\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    \n",
    "    \n",
    "memory = ReplayMemory(MEMORY_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRIORITY = 3\n",
    "\n",
    "def train(net, train_iter,criterion, num_epochs, device,lr=None, weight_decay = 0):\n",
    "\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        #train_l_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        #train_loss_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        train_l_sum = 0.0\n",
    "        train_loss_sum = 0.0\n",
    "        \n",
    "        \n",
    "        n, start = 0, time.time()\n",
    "\n",
    "        for x, y in train_iter:\n",
    "            net.train()\n",
    "            optimizer.zero_grad()\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            \n",
    "            y_hat = net(x)\n",
    "            loss = criterion(y[:7], y_hat[:7]) + PRIORITY * criterion(y[7:],y_hat[7:])\n",
    "            #loss = criterion(torch.atanh(y), torch.atanh(y_hat))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                train_l_sum += loss.float()\n",
    "                train_loss_sum += sum([abs(unpack(d)) for d in (y-y_hat)])\n",
    "                n += 1\n",
    "\n",
    "\n",
    "        print('epoch %d, loss %.4f, train loss %.3f, time %.1f sec, n=%d' %\n",
    "              (epoch + 1, train_l_sum/n*SCALE, train_loss_sum/n, time.time() - start, n) )\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "criterion = nn.MSELoss(reduction = 'sum')\n",
    "train(net, train_data, criterion,1000, device, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.save(net.state_dict(), './data/HM_learn_scores_' + str(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net.load_state_dict(torch.load('./data/HM_learn_scores_1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr = 0\n",
    "\n",
    "for x,y in train_data:\n",
    "    net.eval()\n",
    "    x,y = x.to(device),y.to(device)\n",
    "    y_hat = net(x)\n",
    "\n",
    "    hy = y.clone().detach()\n",
    "    hyh = y_hat.clone().detach()\n",
    "    \n",
    "    dh = (hy-hyh)\n",
    "    \n",
    "    flag = False\n",
    "\n",
    "    \n",
    "    for i in range(OUTPUT_SIZE):\n",
    "        if not unpack(dh[i]) == 0:\n",
    "            flag = True\n",
    "            break\n",
    "    \n",
    "    if not flag:\n",
    "        corr += 1\n",
    "        continue\n",
    "    \n",
    "    cont = \"\"\n",
    "    for a in x:\n",
    "        cont += str(int(a)) + \" \"\n",
    "    cont += \" | \"\n",
    "    for d in hy-hyh:\n",
    "    #for d in hyh:\n",
    "        cont += str(unpack(d)) + \" \"\n",
    "    print(cont)\n",
    "        \n",
    "print(\"{0}\".format(corr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = [0]\n",
    "def select_action(Qv, is_step = False, with_random = True):\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done[0] / EPS_DECAY)\n",
    "    \n",
    "    if is_step:\n",
    "        steps_done[0] += 1\n",
    "\n",
    "    if not with_random or sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return int(torch.argmax(Qv,0))+31\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(D_OUTPUT_SIZE)+31]], device=device, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_scores = []\n",
    "\n",
    "def plot_scores():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    scores_t = torch.tensor(episode_scores, dtype=torch.float32)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Score')\n",
    "    plt.plot(scores_t.numpy())\n",
    "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
    "    if len(scores_t) >= 10:\n",
    "        means = scores_t.unfold(0, 10, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(9), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    ip.display.clear_output(wait=True)\n",
    "    plt.pause(0.001)  # 도표가 업데이트되도록 잠시 멈춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_step(pol_net, tar_net, optimizer, criterion):\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    \n",
    "    batch = memory.sample(BATCH_SIZE)\n",
    "    #batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    for transition in batch:\n",
    "        Q_state = pol_net(transition.state)\n",
    "        Q_next_max = 0 if transition.next_state == None else torch.max(tar_net(transition.next_state),0)[0]\n",
    "        expected_action_value = Q_next_max * GAMMA + transition.reward\n",
    "        \n",
    "        loss += criterion(Q_state[transition.action-31].view(1), expected_action_value)\n",
    "        #print(\"{0}<<left | right>>{1}\".format(Q_state[transition.action-31], expected_action_value))\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveidx = 0\n",
    "def D_train(pol_net, tar_net, criterion, num_episodes, device,lr=None, weight_decay = 0):\n",
    "    \n",
    "    optimizer = optim.SGD(pol_net.parameters(),lr=lr)\n",
    "    pol_net.train()\n",
    "    \n",
    "    for i_episode in range(num_episodes):\n",
    "        \n",
    "        yacht.reset_game()\n",
    "        state, score, _ = yacht.get_yacht_output()\n",
    "        state = torch.tensor(state[:12]+state[18:6+D_INPUT_SIZE], dtype=torch.float32, device=device, requires_grad = False)\n",
    "        \n",
    "        while True:\n",
    "            Qv = pol_net(state)\n",
    "            action = select_action(Qv, is_step = True)\n",
    "            reward = yacht.update(action)/SCALE\n",
    "\n",
    "            new_state, new_score, done = yacht.get_yacht_output()\n",
    "            step_reward = torch.tensor([float(reward)], device=device, requires_grad = False)\n",
    "\n",
    "            if not done:\n",
    "                new_state = torch.tensor(new_state[:12]+new_state[18:6+D_INPUT_SIZE], dtype=torch.float, device=device, requires_grad = False)\n",
    "            else:\n",
    "                new_state = None\n",
    "            \n",
    "            memory.push(state,action,new_state,step_reward)\n",
    "\n",
    "            state = new_state\n",
    "            score = new_score\n",
    "\n",
    "            optimize_step(pol_net, tar_net, optimizer,criterion)\n",
    "\n",
    "            if done:\n",
    "                state, score, _ = yacht.get_yacht_output()\n",
    "                episode_scores.append(score)\n",
    "                #print(\"{0}) {1}\\tscore : {2}, turns = {3}\".format(i_episode, state[:12], score, t+1))\n",
    "\n",
    "                if i_episode % 10 == 0:\n",
    "                    plot_scores()\n",
    "\n",
    "                break\n",
    "\n",
    "        #목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
    "\n",
    "        if i_episode % TARGET_UPDATE == 0:\n",
    "            tar_net.load_state_dict(pol_net.state_dict())\n",
    "        if i_episode % 10000 == 9999:\n",
    "            saveidx += 1\n",
    "            torch.save(pol_net.state_dict(), './data/HM_DQN/' + str(saveidx))\n",
    "        \n",
    "        #print(\"episode {0} finished\".format(i_episode))\n",
    "\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[13]' is invalid for input of size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4c4f8bcea724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mD_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#comment: 500단위로 감마 올려서 잠깐 팍 떨어지는 구간 있음. 각각 감마 0->0.1->0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-222270561aa0>\u001b[0m in \u001b[0;36mD_train\u001b[1;34m(pol_net, tar_net, criterion, num_episodes, device, lr, weight_decay)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mQv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpol_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myacht\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ss20181116001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ss20181116001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ss20181116001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-978c72b4bd88>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mD_Reshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_INPUT_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m policy_net = torch.nn.Sequential(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[13]' is invalid for input of size 12"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "D_train(policy_net, target_net, criterion, 500,device, lr = 0.0001)\n",
    "#comment: 500단위로 감마 올려서 잠깐 팍 떨어지는 구간 있음. 각각 감마 0->0.1->0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveidx += 1\n",
    "torch.save(policy_net.state_dict(), './data/HM_DQN/' + str(saveidx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht.reset_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo = yacht.get_yacht_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0, 4, 0, 12, 19, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 0, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=yo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0, 4, 0, 12, 19, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st[:12]+st[18:6+D_INPUT_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
