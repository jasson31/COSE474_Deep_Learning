{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "#import d2l\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy\n",
    "import yacht_main as yacht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Reshape()\n",
       "  (1): Linear(in_features=6, out_features=50, bias=True)\n",
       "  (2): LeakyReLU(negative_slope=0.01)\n",
       "  (3): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (4): LeakyReLU(negative_slope=0.01)\n",
       "  (5): Linear(in_features=30, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SIZE = 6\n",
    "OUTPUT_SIZE = 12\n",
    "\n",
    "class Reshape(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(INPUT_SIZE)\n",
    "    \n",
    "net = torch.nn.Sequential(\n",
    "    Reshape(),\n",
    "    \n",
    "    nn.Linear(in_features=INPUT_SIZE, out_features=50),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(50,30),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(30,OUTPUT_SIZE)\n",
    "    \n",
    "    #nn.Linear(in_features=INPUT_SIZE, out_features = OUTPUT_SIZE)\n",
    ")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.uniform_(m.weight,-0.5,0.5)\n",
    "\n",
    "net = net.float()\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def try_gpu():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "device = try_gpu()\n",
    "print(torch.cuda.is_available())\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "0 0 0 0 0 5  | 0 0 0 0 0 30 30 30 30 0 0 50 \n",
      "0 0 0 0 1 4  | 0 0 0 0 5 24 29 29 0 0 0 0 \n",
      "0 0 0 0 2 3  | 0 0 0 0 10 18 28 0 28 0 0 0 \n",
      "0 0 0 0 3 2  | 0 0 0 0 15 12 27 0 27 0 0 0 \n",
      "0 0 0 0 4 1  | 0 0 0 0 20 6 26 26 0 0 0 0 \n",
      "0 0 0 0 5 0  | 0 0 0 0 25 0 25 25 25 0 0 50 \n",
      "0 0 0 1 0 4  | 0 0 0 4 0 24 28 28 0 0 0 0 \n",
      "0 0 0 1 1 3  | 0 0 0 4 5 18 27 0 0 0 0 0 \n",
      "0 0 0 1 2 2  | 0 0 0 4 10 12 26 0 0 0 0 0 \n",
      "0 0 0 1 3 1  | 0 0 0 4 15 6 25 0 0 0 0 0 \n",
      "0 0 0 1 4 0  | 0 0 0 4 20 0 24 24 0 0 0 0 \n",
      "0 0 0 2 0 3  | 0 0 0 8 0 18 26 0 26 0 0 0 \n",
      "0 0 0 2 1 2  | 0 0 0 8 5 12 25 0 0 0 0 0 \n",
      "0 0 0 2 2 1  | 0 0 0 8 10 6 24 0 0 0 0 0 \n",
      "0 0 0 2 3 0  | 0 0 0 8 15 0 23 0 23 0 0 0 \n",
      "0 0 0 3 0 2  | 0 0 0 12 0 12 24 0 24 0 0 0 \n",
      "0 0 0 3 1 1  | 0 0 0 12 5 6 23 0 0 0 0 0 \n",
      "0 0 0 3 2 0  | 0 0 0 12 10 0 22 0 22 0 0 0 \n",
      "0 0 0 4 0 1  | 0 0 0 16 0 6 22 22 0 0 0 0 \n",
      "0 0 0 4 1 0  | 0 0 0 16 5 0 21 21 0 0 0 0 \n",
      "0 0 0 5 0 0  | 0 0 0 20 0 0 20 20 20 0 0 50 \n",
      "0 0 1 0 0 4  | 0 0 3 0 0 24 27 27 0 0 0 0 \n",
      "0 0 1 0 1 3  | 0 0 3 0 5 18 26 0 0 0 0 0 \n",
      "0 0 1 0 2 2  | 0 0 3 0 10 12 25 0 0 0 0 0 \n",
      "0 0 1 0 3 1  | 0 0 3 0 15 6 24 0 0 0 0 0 \n",
      "0 0 1 0 4 0  | 0 0 3 0 20 0 23 23 0 0 0 0 \n",
      "0 0 1 1 0 3  | 0 0 3 4 0 18 25 0 0 0 0 0 \n",
      "0 0 1 1 1 2  | 0 0 3 4 5 12 24 0 0 15 0 0 \n",
      "0 0 1 1 2 1  | 0 0 3 4 10 6 23 0 0 15 0 0 \n",
      "0 0 1 1 3 0  | 0 0 3 4 15 0 22 0 0 0 0 0 \n",
      "0 0 1 2 0 2  | 0 0 3 8 0 12 23 0 0 0 0 0 \n",
      "0 0 1 2 1 1  | 0 0 3 8 5 6 22 0 0 15 0 0 \n",
      "0 0 1 2 2 0  | 0 0 3 8 10 0 21 0 0 0 0 0 \n",
      "0 0 1 3 0 1  | 0 0 3 12 0 6 21 0 0 0 0 0 \n",
      "0 0 1 3 1 0  | 0 0 3 12 5 0 20 0 0 0 0 0 \n",
      "0 0 1 4 0 0  | 0 0 3 16 0 0 19 19 0 0 0 0 \n",
      "0 0 2 0 0 3  | 0 0 6 0 0 18 24 0 24 0 0 0 \n",
      "0 0 2 0 1 2  | 0 0 6 0 5 12 23 0 0 0 0 0 \n",
      "0 0 2 0 2 1  | 0 0 6 0 10 6 22 0 0 0 0 0 \n",
      "0 0 2 0 3 0  | 0 0 6 0 15 0 21 0 21 0 0 0 \n",
      "0 0 2 1 0 2  | 0 0 6 4 0 12 22 0 0 0 0 0 \n",
      "0 0 2 1 1 1  | 0 0 6 4 5 6 21 0 0 15 0 0 \n",
      "0 0 2 1 2 0  | 0 0 6 4 10 0 20 0 0 0 0 0 \n",
      "0 0 2 2 0 1  | 0 0 6 8 0 6 20 0 0 0 0 0 \n",
      "0 0 2 2 1 0  | 0 0 6 8 5 0 19 0 0 0 0 0 \n",
      "0 0 2 3 0 0  | 0 0 6 12 0 0 18 0 18 0 0 0 \n",
      "0 0 3 0 0 2  | 0 0 9 0 0 12 21 0 21 0 0 0 \n",
      "0 0 3 0 1 1  | 0 0 9 0 5 6 20 0 0 0 0 0 \n",
      "0 0 3 0 2 0  | 0 0 9 0 10 0 19 0 19 0 0 0 \n",
      "0 0 3 1 0 1  | 0 0 9 4 0 6 19 0 0 0 0 0 \n",
      "0 0 3 1 1 0  | 0 0 9 4 5 0 18 0 0 0 0 0 \n",
      "0 0 3 2 0 0  | 0 0 9 8 0 0 17 0 17 0 0 0 \n",
      "0 0 4 0 0 1  | 0 0 12 0 0 6 18 18 0 0 0 0 \n",
      "0 0 4 0 1 0  | 0 0 12 0 5 0 17 17 0 0 0 0 \n",
      "0 0 4 1 0 0  | 0 0 12 4 0 0 16 16 0 0 0 0 \n",
      "0 0 5 0 0 0  | 0 0 15 0 0 0 15 15 15 0 0 50 \n",
      "0 1 0 0 0 4  | 0 2 0 0 0 24 26 26 0 0 0 0 \n",
      "0 1 0 0 1 3  | 0 2 0 0 5 18 25 0 0 0 0 0 \n",
      "0 1 0 0 2 2  | 0 2 0 0 10 12 24 0 0 0 0 0 \n",
      "0 1 0 0 3 1  | 0 2 0 0 15 6 23 0 0 0 0 0 \n",
      "0 1 0 0 4 0  | 0 2 0 0 20 0 22 22 0 0 0 0 \n",
      "0 1 0 1 0 3  | 0 2 0 4 0 18 24 0 0 0 0 0 \n",
      "0 1 0 1 1 2  | 0 2 0 4 5 12 23 0 0 0 0 0 \n",
      "0 1 0 1 2 1  | 0 2 0 4 10 6 22 0 0 0 0 0 \n",
      "0 1 0 1 3 0  | 0 2 0 4 15 0 21 0 0 0 0 0 \n",
      "0 1 0 2 0 2  | 0 2 0 8 0 12 22 0 0 0 0 0 \n",
      "0 1 0 2 1 1  | 0 2 0 8 5 6 21 0 0 0 0 0 \n",
      "0 1 0 2 2 0  | 0 2 0 8 10 0 20 0 0 0 0 0 \n",
      "0 1 0 3 0 1  | 0 2 0 12 0 6 20 0 0 0 0 0 \n",
      "0 1 0 3 1 0  | 0 2 0 12 5 0 19 0 0 0 0 0 \n",
      "0 1 0 4 0 0  | 0 2 0 16 0 0 18 18 0 0 0 0 \n",
      "0 1 1 0 0 3  | 0 2 3 0 0 18 23 0 0 0 0 0 \n",
      "0 1 1 0 1 2  | 0 2 3 0 5 12 22 0 0 0 0 0 \n",
      "0 1 1 0 2 1  | 0 2 3 0 10 6 21 0 0 0 0 0 \n",
      "0 1 1 0 3 0  | 0 2 3 0 15 0 20 0 0 0 0 0 \n",
      "0 1 1 1 0 2  | 0 2 3 4 0 12 21 0 0 0 0 0 \n",
      "0 1 1 1 1 1  | 0 2 3 4 5 6 20 0 0 15 30 0 \n",
      "0 1 1 1 2 0  | 0 2 3 4 10 0 19 0 0 15 0 0 \n",
      "0 1 1 2 0 1  | 0 2 3 8 0 6 19 0 0 0 0 0 \n",
      "0 1 1 2 1 0  | 0 2 3 8 5 0 18 0 0 15 0 0 \n",
      "0 1 1 3 0 0  | 0 2 3 12 0 0 17 0 0 0 0 0 \n",
      "0 1 2 0 0 2  | 0 2 6 0 0 12 20 0 0 0 0 0 \n",
      "0 1 2 0 1 1  | 0 2 6 0 5 6 19 0 0 0 0 0 \n",
      "0 1 2 0 2 0  | 0 2 6 0 10 0 18 0 0 0 0 0 \n",
      "0 1 2 1 0 1  | 0 2 6 4 0 6 18 0 0 0 0 0 \n",
      "0 1 2 1 1 0  | 0 2 6 4 5 0 17 0 0 15 0 0 \n",
      "0 1 2 2 0 0  | 0 2 6 8 0 0 16 0 0 0 0 0 \n",
      "0 1 3 0 0 1  | 0 2 9 0 0 6 17 0 0 0 0 0 \n",
      "0 1 3 0 1 0  | 0 2 9 0 5 0 16 0 0 0 0 0 \n",
      "0 1 3 1 0 0  | 0 2 9 4 0 0 15 0 0 0 0 0 \n",
      "0 1 4 0 0 0  | 0 2 12 0 0 0 14 14 0 0 0 0 \n",
      "0 2 0 0 0 3  | 0 4 0 0 0 18 22 0 22 0 0 0 \n",
      "0 2 0 0 1 2  | 0 4 0 0 5 12 21 0 0 0 0 0 \n",
      "0 2 0 0 2 1  | 0 4 0 0 10 6 20 0 0 0 0 0 \n",
      "0 2 0 0 3 0  | 0 4 0 0 15 0 19 0 19 0 0 0 \n",
      "0 2 0 1 0 2  | 0 4 0 4 0 12 20 0 0 0 0 0 \n",
      "0 2 0 1 1 1  | 0 4 0 4 5 6 19 0 0 0 0 0 \n",
      "0 2 0 1 2 0  | 0 4 0 4 10 0 18 0 0 0 0 0 \n",
      "0 2 0 2 0 1  | 0 4 0 8 0 6 18 0 0 0 0 0 \n",
      "0 2 0 2 1 0  | 0 4 0 8 5 0 17 0 0 0 0 0 \n",
      "0 2 0 3 0 0  | 0 4 0 12 0 0 16 0 16 0 0 0 \n",
      "0 2 1 0 0 2  | 0 4 3 0 0 12 19 0 0 0 0 0 \n",
      "0 2 1 0 1 1  | 0 4 3 0 5 6 18 0 0 0 0 0 \n",
      "0 2 1 0 2 0  | 0 4 3 0 10 0 17 0 0 0 0 0 \n",
      "0 2 1 1 0 1  | 0 4 3 4 0 6 17 0 0 0 0 0 \n",
      "0 2 1 1 1 0  | 0 4 3 4 5 0 16 0 0 15 0 0 \n",
      "0 2 1 2 0 0  | 0 4 3 8 0 0 15 0 0 0 0 0 \n",
      "0 2 2 0 0 1  | 0 4 6 0 0 6 16 0 0 0 0 0 \n",
      "0 2 2 0 1 0  | 0 4 6 0 5 0 15 0 0 0 0 0 \n",
      "0 2 2 1 0 0  | 0 4 6 4 0 0 14 0 0 0 0 0 \n",
      "0 2 3 0 0 0  | 0 4 9 0 0 0 13 0 13 0 0 0 \n",
      "0 3 0 0 0 2  | 0 6 0 0 0 12 18 0 18 0 0 0 \n",
      "0 3 0 0 1 1  | 0 6 0 0 5 6 17 0 0 0 0 0 \n",
      "0 3 0 0 2 0  | 0 6 0 0 10 0 16 0 16 0 0 0 \n",
      "0 3 0 1 0 1  | 0 6 0 4 0 6 16 0 0 0 0 0 \n",
      "0 3 0 1 1 0  | 0 6 0 4 5 0 15 0 0 0 0 0 \n",
      "0 3 0 2 0 0  | 0 6 0 8 0 0 14 0 14 0 0 0 \n",
      "0 3 1 0 0 1  | 0 6 3 0 0 6 15 0 0 0 0 0 \n",
      "0 3 1 0 1 0  | 0 6 3 0 5 0 14 0 0 0 0 0 \n",
      "0 3 1 1 0 0  | 0 6 3 4 0 0 13 0 0 0 0 0 \n",
      "0 3 2 0 0 0  | 0 6 6 0 0 0 12 0 12 0 0 0 \n",
      "0 4 0 0 0 1  | 0 8 0 0 0 6 14 14 0 0 0 0 \n",
      "0 4 0 0 1 0  | 0 8 0 0 5 0 13 13 0 0 0 0 \n",
      "0 4 0 1 0 0  | 0 8 0 4 0 0 12 12 0 0 0 0 \n",
      "0 4 1 0 0 0  | 0 8 3 0 0 0 11 11 0 0 0 0 \n",
      "0 5 0 0 0 0  | 0 10 0 0 0 0 10 10 10 0 0 50 \n",
      "1 0 0 0 0 4  | 1 0 0 0 0 24 25 25 0 0 0 0 \n",
      "1 0 0 0 1 3  | 1 0 0 0 5 18 24 0 0 0 0 0 \n",
      "1 0 0 0 2 2  | 1 0 0 0 10 12 23 0 0 0 0 0 \n",
      "1 0 0 0 3 1  | 1 0 0 0 15 6 22 0 0 0 0 0 \n",
      "1 0 0 0 4 0  | 1 0 0 0 20 0 21 21 0 0 0 0 \n",
      "1 0 0 1 0 3  | 1 0 0 4 0 18 23 0 0 0 0 0 \n",
      "1 0 0 1 1 2  | 1 0 0 4 5 12 22 0 0 0 0 0 \n",
      "1 0 0 1 2 1  | 1 0 0 4 10 6 21 0 0 0 0 0 \n",
      "1 0 0 1 3 0  | 1 0 0 4 15 0 20 0 0 0 0 0 \n",
      "1 0 0 2 0 2  | 1 0 0 8 0 12 21 0 0 0 0 0 \n",
      "1 0 0 2 1 1  | 1 0 0 8 5 6 20 0 0 0 0 0 \n",
      "1 0 0 2 2 0  | 1 0 0 8 10 0 19 0 0 0 0 0 \n",
      "1 0 0 3 0 1  | 1 0 0 12 0 6 19 0 0 0 0 0 \n",
      "1 0 0 3 1 0  | 1 0 0 12 5 0 18 0 0 0 0 0 \n",
      "1 0 0 4 0 0  | 1 0 0 16 0 0 17 17 0 0 0 0 \n",
      "1 0 1 0 0 3  | 1 0 3 0 0 18 22 0 0 0 0 0 \n",
      "1 0 1 0 1 2  | 1 0 3 0 5 12 21 0 0 0 0 0 \n",
      "1 0 1 0 2 1  | 1 0 3 0 10 6 20 0 0 0 0 0 \n",
      "1 0 1 0 3 0  | 1 0 3 0 15 0 19 0 0 0 0 0 \n",
      "1 0 1 1 0 2  | 1 0 3 4 0 12 20 0 0 0 0 0 \n",
      "1 0 1 1 1 1  | 1 0 3 4 5 6 19 0 0 0 0 0 \n",
      "1 0 1 1 2 0  | 1 0 3 4 10 0 18 0 0 0 0 0 \n",
      "1 0 1 2 0 1  | 1 0 3 8 0 6 18 0 0 0 0 0 \n",
      "1 0 1 2 1 0  | 1 0 3 8 5 0 17 0 0 0 0 0 \n",
      "1 0 1 3 0 0  | 1 0 3 12 0 0 16 0 0 0 0 0 \n",
      "1 0 2 0 0 2  | 1 0 6 0 0 12 19 0 0 0 0 0 \n",
      "1 0 2 0 1 1  | 1 0 6 0 5 6 18 0 0 0 0 0 \n",
      "1 0 2 0 2 0  | 1 0 6 0 10 0 17 0 0 0 0 0 \n",
      "1 0 2 1 0 1  | 1 0 6 4 0 6 17 0 0 0 0 0 \n",
      "1 0 2 1 1 0  | 1 0 6 4 5 0 16 0 0 0 0 0 \n",
      "1 0 2 2 0 0  | 1 0 6 8 0 0 15 0 0 0 0 0 \n",
      "1 0 3 0 0 1  | 1 0 9 0 0 6 16 0 0 0 0 0 \n",
      "1 0 3 0 1 0  | 1 0 9 0 5 0 15 0 0 0 0 0 \n",
      "1 0 3 1 0 0  | 1 0 9 4 0 0 14 0 0 0 0 0 \n",
      "1 0 4 0 0 0  | 1 0 12 0 0 0 13 13 0 0 0 0 \n",
      "1 1 0 0 0 3  | 1 2 0 0 0 18 21 0 0 0 0 0 \n",
      "1 1 0 0 1 2  | 1 2 0 0 5 12 20 0 0 0 0 0 \n",
      "1 1 0 0 2 1  | 1 2 0 0 10 6 19 0 0 0 0 0 \n",
      "1 1 0 0 3 0  | 1 2 0 0 15 0 18 0 0 0 0 0 \n",
      "1 1 0 1 0 2  | 1 2 0 4 0 12 19 0 0 0 0 0 \n",
      "1 1 0 1 1 1  | 1 2 0 4 5 6 18 0 0 0 0 0 \n",
      "1 1 0 1 2 0  | 1 2 0 4 10 0 17 0 0 0 0 0 \n",
      "1 1 0 2 0 1  | 1 2 0 8 0 6 17 0 0 0 0 0 \n",
      "1 1 0 2 1 0  | 1 2 0 8 5 0 16 0 0 0 0 0 \n",
      "1 1 0 3 0 0  | 1 2 0 12 0 0 15 0 0 0 0 0 \n",
      "1 1 1 0 0 2  | 1 2 3 0 0 12 18 0 0 0 0 0 \n",
      "1 1 1 0 1 1  | 1 2 3 0 5 6 17 0 0 0 0 0 \n",
      "1 1 1 0 2 0  | 1 2 3 0 10 0 16 0 0 0 0 0 \n",
      "1 1 1 1 0 1  | 1 2 3 4 0 6 16 0 0 15 0 0 \n",
      "1 1 1 1 1 0  | 1 2 3 4 5 0 15 0 0 15 30 0 \n",
      "1 1 1 2 0 0  | 1 2 3 8 0 0 14 0 0 15 0 0 \n",
      "1 1 2 0 0 1  | 1 2 6 0 0 6 15 0 0 0 0 0 \n",
      "1 1 2 0 1 0  | 1 2 6 0 5 0 14 0 0 0 0 0 \n",
      "1 1 2 1 0 0  | 1 2 6 4 0 0 13 0 0 15 0 0 \n",
      "1 1 3 0 0 0  | 1 2 9 0 0 0 12 0 0 0 0 0 \n",
      "1 2 0 0 0 2  | 1 4 0 0 0 12 17 0 0 0 0 0 \n",
      "1 2 0 0 1 1  | 1 4 0 0 5 6 16 0 0 0 0 0 \n",
      "1 2 0 0 2 0  | 1 4 0 0 10 0 15 0 0 0 0 0 \n",
      "1 2 0 1 0 1  | 1 4 0 4 0 6 15 0 0 0 0 0 \n",
      "1 2 0 1 1 0  | 1 4 0 4 5 0 14 0 0 0 0 0 \n",
      "1 2 0 2 0 0  | 1 4 0 8 0 0 13 0 0 0 0 0 \n",
      "1 2 1 0 0 1  | 1 4 3 0 0 6 14 0 0 0 0 0 \n",
      "1 2 1 0 1 0  | 1 4 3 0 5 0 13 0 0 0 0 0 \n",
      "1 2 1 1 0 0  | 1 4 3 4 0 0 12 0 0 15 0 0 \n",
      "1 2 2 0 0 0  | 1 4 6 0 0 0 11 0 0 0 0 0 \n",
      "1 3 0 0 0 1  | 1 6 0 0 0 6 13 0 0 0 0 0 \n",
      "1 3 0 0 1 0  | 1 6 0 0 5 0 12 0 0 0 0 0 \n",
      "1 3 0 1 0 0  | 1 6 0 4 0 0 11 0 0 0 0 0 \n",
      "1 3 1 0 0 0  | 1 6 3 0 0 0 10 0 0 0 0 0 \n",
      "1 4 0 0 0 0  | 1 8 0 0 0 0 9 9 0 0 0 0 \n",
      "2 0 0 0 0 3  | 2 0 0 0 0 18 20 0 20 0 0 0 \n",
      "2 0 0 0 1 2  | 2 0 0 0 5 12 19 0 0 0 0 0 \n",
      "2 0 0 0 2 1  | 2 0 0 0 10 6 18 0 0 0 0 0 \n",
      "2 0 0 0 3 0  | 2 0 0 0 15 0 17 0 17 0 0 0 \n",
      "2 0 0 1 0 2  | 2 0 0 4 0 12 18 0 0 0 0 0 \n",
      "2 0 0 1 1 1  | 2 0 0 4 5 6 17 0 0 0 0 0 \n",
      "2 0 0 1 2 0  | 2 0 0 4 10 0 16 0 0 0 0 0 \n",
      "2 0 0 2 0 1  | 2 0 0 8 0 6 16 0 0 0 0 0 \n",
      "2 0 0 2 1 0  | 2 0 0 8 5 0 15 0 0 0 0 0 \n",
      "2 0 0 3 0 0  | 2 0 0 12 0 0 14 0 14 0 0 0 \n",
      "2 0 1 0 0 2  | 2 0 3 0 0 12 17 0 0 0 0 0 \n",
      "2 0 1 0 1 1  | 2 0 3 0 5 6 16 0 0 0 0 0 \n",
      "2 0 1 0 2 0  | 2 0 3 0 10 0 15 0 0 0 0 0 \n",
      "2 0 1 1 0 1  | 2 0 3 4 0 6 15 0 0 0 0 0 \n",
      "2 0 1 1 1 0  | 2 0 3 4 5 0 14 0 0 0 0 0 \n",
      "2 0 1 2 0 0  | 2 0 3 8 0 0 13 0 0 0 0 0 \n",
      "2 0 2 0 0 1  | 2 0 6 0 0 6 14 0 0 0 0 0 \n",
      "2 0 2 0 1 0  | 2 0 6 0 5 0 13 0 0 0 0 0 \n",
      "2 0 2 1 0 0  | 2 0 6 4 0 0 12 0 0 0 0 0 \n",
      "2 0 3 0 0 0  | 2 0 9 0 0 0 11 0 11 0 0 0 \n",
      "2 1 0 0 0 2  | 2 2 0 0 0 12 16 0 0 0 0 0 \n",
      "2 1 0 0 1 1  | 2 2 0 0 5 6 15 0 0 0 0 0 \n",
      "2 1 0 0 2 0  | 2 2 0 0 10 0 14 0 0 0 0 0 \n",
      "2 1 0 1 0 1  | 2 2 0 4 0 6 14 0 0 0 0 0 \n",
      "2 1 0 1 1 0  | 2 2 0 4 5 0 13 0 0 0 0 0 \n",
      "2 1 0 2 0 0  | 2 2 0 8 0 0 12 0 0 0 0 0 \n",
      "2 1 1 0 0 1  | 2 2 3 0 0 6 13 0 0 0 0 0 \n",
      "2 1 1 0 1 0  | 2 2 3 0 5 0 12 0 0 0 0 0 \n",
      "2 1 1 1 0 0  | 2 2 3 4 0 0 11 0 0 15 0 0 \n",
      "2 1 2 0 0 0  | 2 2 6 0 0 0 10 0 0 0 0 0 \n",
      "2 2 0 0 0 1  | 2 4 0 0 0 6 12 0 0 0 0 0 \n",
      "2 2 0 0 1 0  | 2 4 0 0 5 0 11 0 0 0 0 0 \n",
      "2 2 0 1 0 0  | 2 4 0 4 0 0 10 0 0 0 0 0 \n",
      "2 2 1 0 0 0  | 2 4 3 0 0 0 9 0 0 0 0 0 \n",
      "2 3 0 0 0 0  | 2 6 0 0 0 0 8 0 8 0 0 0 \n",
      "3 0 0 0 0 2  | 3 0 0 0 0 12 15 0 15 0 0 0 \n",
      "3 0 0 0 1 1  | 3 0 0 0 5 6 14 0 0 0 0 0 \n",
      "3 0 0 0 2 0  | 3 0 0 0 10 0 13 0 13 0 0 0 \n",
      "3 0 0 1 0 1  | 3 0 0 4 0 6 13 0 0 0 0 0 \n",
      "3 0 0 1 1 0  | 3 0 0 4 5 0 12 0 0 0 0 0 \n",
      "3 0 0 2 0 0  | 3 0 0 8 0 0 11 0 11 0 0 0 \n",
      "3 0 1 0 0 1  | 3 0 3 0 0 6 12 0 0 0 0 0 \n",
      "3 0 1 0 1 0  | 3 0 3 0 5 0 11 0 0 0 0 0 \n",
      "3 0 1 1 0 0  | 3 0 3 4 0 0 10 0 0 0 0 0 \n",
      "3 0 2 0 0 0  | 3 0 6 0 0 0 9 0 9 0 0 0 \n",
      "3 1 0 0 0 1  | 3 2 0 0 0 6 11 0 0 0 0 0 \n",
      "3 1 0 0 1 0  | 3 2 0 0 5 0 10 0 0 0 0 0 \n",
      "3 1 0 1 0 0  | 3 2 0 4 0 0 9 0 0 0 0 0 \n",
      "3 1 1 0 0 0  | 3 2 3 0 0 0 8 0 0 0 0 0 \n",
      "3 2 0 0 0 0  | 3 4 0 0 0 0 7 0 7 0 0 0 \n",
      "4 0 0 0 0 1  | 4 0 0 0 0 6 10 10 0 0 0 0 \n",
      "4 0 0 0 1 0  | 4 0 0 0 5 0 9 9 0 0 0 0 \n",
      "4 0 0 1 0 0  | 4 0 0 4 0 0 8 8 0 0 0 0 \n",
      "4 0 1 0 0 0  | 4 0 3 0 0 0 7 7 0 0 0 0 \n",
      "4 1 0 0 0 0  | 4 2 0 0 0 0 6 6 0 0 0 0 \n",
      "5 0 0 0 0 0  | 5 0 0 0 0 0 5 5 5 0 0 50 \n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "SCALE = 30.0\n",
    "\n",
    "\n",
    "def pack(org):\n",
    "    return (org/SCALE)\n",
    "\n",
    "def unpack(norm):\n",
    "    if math.isnan(norm):\n",
    "        return float(100)\n",
    "    return round(SCALE*float(norm))\n",
    "\"\"\"\n",
    "for d1 in range(6):\n",
    "    for d2 in range(6):\n",
    "        for d3 in range(6):\n",
    "            for d4 in range(6):\n",
    "                for d5 in range(6):\n",
    "                    dices = [d1+1,d2+1,d3+1,d4+1,d5+1]\n",
    "                    scores = [pack(f(dices)) for f in yacht.score_func]\n",
    "                    #scores = [yacht.score_func[6](dices)/SCALE]\n",
    "                    \n",
    "                    dt = torch.tensor([dices.count(i+1)/5.0 for i in range(6)], dtype = torch.float32, requires_grad = False)\n",
    "                    st = torch.tensor(scores, dtype = torch.float32, requires_grad = False)\n",
    "                    \n",
    "                    train_data.append((dt,st))\n",
    "\"\"\"\n",
    "\n",
    "for c1 in range(6):\n",
    "    for c2 in range(6-c1):\n",
    "        for c3 in range(6-c1-c2):\n",
    "            for c4 in range(6-c1-c2-c3):\n",
    "                for c5 in range(6-c1-c2-c3-c4):\n",
    "                    c6 = 5-c1-c2-c3-c4-c5\n",
    "                    dices = [1]*c1 + [2]*c2 + [3]*c3 + [4]*c4 + [5]*c5 + [6]*c6\n",
    "\n",
    "                    scores = [pack(f(dices)) for f in yacht.score_func]\n",
    "                    #scores = [yacht.score_func[6](dices)/SCALE]\n",
    "\n",
    "                    dt = torch.tensor([c1,c2,c3,c4,c5,c6], dtype = torch.float32, requires_grad = False)\n",
    "                    st = torch.tensor(scores, dtype = torch.float32, requires_grad = False)\n",
    "\n",
    "                    train_data.append((dt/5.0,st))\n",
    "\n",
    "print(str(len(train_data)))\n",
    "\n",
    "for x,y in train_data:\n",
    "    cont = \"\"\n",
    "    for a in x:\n",
    "        cont += str(int(a*5))+\" \"\n",
    "    cont += \" | \"\n",
    "    for b in y:\n",
    "        cont += str(unpack(b))+\" \"\n",
    "    print(cont)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIORITY = 3\n",
    "saveidx = 0\n",
    "def train(net, train_iter,criterion, num_epochs, device,lr=None, weight_decay = 0):\n",
    "\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        #train_l_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        #train_loss_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        train_l_sum = 0.0\n",
    "        train_loss_sum = 0.0\n",
    "        \n",
    "        \n",
    "        n, start = 0, time.time()\n",
    "\n",
    "        for x, y in train_iter:\n",
    "            net.train()\n",
    "            optimizer.zero_grad()\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            \n",
    "            y_hat = net(x)\n",
    "            loss = criterion(y[:7], y_hat[:7]) + PRIORITY * criterion(y[7:],y_hat[7:])\n",
    "            #loss = criterion(torch.atanh(y), torch.atanh(y_hat))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                train_l_sum += loss.float()\n",
    "                train_loss_sum += sum([abs(unpack(d)) for d in (y-y_hat)])\n",
    "                n += 1\n",
    "\n",
    "        print('epoch %d, loss %.4f, train loss %.3f, time %.1f sec, n=%d' %\n",
    "              (epoch + 1, 100.0*train_l_sum/n*SCALE, train_loss_sum/n, time.time() - start, n) )\n",
    "        \n",
    "    saveidx+=1\n",
    "    torch.save(net.state_dict(), './data/HM_learn_scores_' + str(saveidx))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n",
      "epoch 1, loss 3.1316, train loss 0.500, time 0.8 sec, n=252\n",
      "epoch 2, loss 3.1315, train loss 0.500, time 0.7 sec, n=252\n",
      "epoch 3, loss 3.1304, train loss 0.500, time 0.7 sec, n=252\n",
      "epoch 4, loss 3.1283, train loss 0.500, time 0.7 sec, n=252\n",
      "epoch 5, loss 3.1299, train loss 0.500, time 0.8 sec, n=252\n",
      "epoch 6, loss 3.1291, train loss 0.500, time 0.9 sec, n=252\n",
      "epoch 7, loss 3.1292, train loss 0.500, time 1.1 sec, n=252\n",
      "epoch 8, loss 3.1281, train loss 0.500, time 0.9 sec, n=252\n",
      "epoch 9, loss 3.1280, train loss 0.500, time 0.7 sec, n=252\n",
      "epoch 10, loss 3.1272, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 11, loss 3.1253, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 12, loss 3.1269, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 13, loss 3.1246, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 14, loss 3.1270, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 15, loss 3.1258, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 16, loss 3.1234, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 17, loss 3.1251, train loss 0.500, time 0.8 sec, n=252\n",
      "epoch 18, loss 3.1248, train loss 0.496, time 0.8 sec, n=252\n",
      "epoch 19, loss 3.1218, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 20, loss 3.1240, train loss 0.500, time 0.7 sec, n=252\n",
      "epoch 21, loss 3.1213, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 22, loss 3.1231, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 23, loss 3.1229, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 24, loss 3.1219, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 25, loss 3.1199, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 26, loss 3.1219, train loss 0.500, time 0.6 sec, n=252\n",
      "epoch 27, loss 3.1190, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 28, loss 3.1202, train loss 0.500, time 0.6 sec, n=252\n",
      "epoch 29, loss 3.1179, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 30, loss 3.1211, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 31, loss 3.1191, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 32, loss 3.1172, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 33, loss 3.1185, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 34, loss 3.1170, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 35, loss 3.1186, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 36, loss 3.1175, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 37, loss 3.1184, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 38, loss 3.1162, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 39, loss 3.1162, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 40, loss 3.1141, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 41, loss 3.1158, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 42, loss 3.1151, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 43, loss 3.1160, train loss 0.500, time 0.6 sec, n=252\n",
      "epoch 44, loss 3.1140, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 45, loss 3.1136, train loss 0.500, time 0.6 sec, n=252\n",
      "epoch 46, loss 3.1120, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 47, loss 3.1136, train loss 0.500, time 0.6 sec, n=252\n",
      "epoch 48, loss 3.1114, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 49, loss 3.1128, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 50, loss 3.1125, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 51, loss 3.1121, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 52, loss 3.1127, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 53, loss 3.1108, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 54, loss 3.1103, train loss 0.500, time 0.6 sec, n=252\n",
      "epoch 55, loss 3.1088, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 56, loss 3.1104, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 57, loss 3.1082, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 58, loss 3.1094, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 59, loss 3.1094, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 60, loss 3.1071, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 61, loss 3.1087, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 62, loss 3.1091, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 63, loss 3.1083, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 64, loss 3.1075, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 65, loss 3.1055, train loss 0.496, time 0.7 sec, n=252\n",
      "epoch 66, loss 3.1072, train loss 0.496, time 0.8 sec, n=252\n",
      "epoch 67, loss 3.1075, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 68, loss 3.1059, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 69, loss 3.1038, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 70, loss 3.1056, train loss 0.500, time 0.6 sec, n=252\n",
      "epoch 71, loss 3.1047, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 72, loss 3.1050, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 73, loss 3.1038, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 74, loss 3.1040, train loss 0.500, time 0.6 sec, n=252\n",
      "epoch 75, loss 3.1012, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 76, loss 3.1036, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 77, loss 3.1020, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 78, loss 3.1020, train loss 0.500, time 0.6 sec, n=252\n",
      "epoch 79, loss 3.1000, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 80, loss 3.1020, train loss 0.500, time 0.6 sec, n=252\n",
      "epoch 81, loss 3.1025, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 82, loss 3.1011, train loss 0.500, time 0.6 sec, n=252\n",
      "epoch 83, loss 3.0991, train loss 0.492, time 0.6 sec, n=252\n",
      "epoch 84, loss 3.1008, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 85, loss 3.0999, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 86, loss 3.1004, train loss 0.488, time 0.6 sec, n=252\n",
      "epoch 87, loss 3.0997, train loss 0.488, time 0.6 sec, n=252\n",
      "epoch 88, loss 3.0976, train loss 0.492, time 0.6 sec, n=252\n",
      "epoch 89, loss 3.0993, train loss 0.492, time 0.6 sec, n=252\n",
      "epoch 90, loss 3.0978, train loss 0.488, time 0.6 sec, n=252\n",
      "epoch 91, loss 3.0975, train loss 0.496, time 0.6 sec, n=252\n",
      "epoch 92, loss 3.0958, train loss 0.488, time 0.6 sec, n=252\n",
      "epoch 93, loss 3.0980, train loss 0.492, time 0.6 sec, n=252\n",
      "epoch 94, loss 3.0968, train loss 0.488, time 0.6 sec, n=252\n",
      "epoch 95, loss 3.0978, train loss 0.488, time 0.6 sec, n=252\n",
      "epoch 96, loss 3.0967, train loss 0.488, time 0.7 sec, n=252\n",
      "epoch 97, loss 3.0946, train loss 0.488, time 0.6 sec, n=252\n",
      "epoch 98, loss 3.0963, train loss 0.488, time 0.6 sec, n=252\n",
      "epoch 99, loss 3.0962, train loss 0.488, time 0.7 sec, n=252\n",
      "epoch 100, loss 3.0951, train loss 0.488, time 0.7 sec, n=252\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'saveidx' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a2be46801a12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-7f1cf5d5f5b1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, train_iter, criterion, num_epochs, device, lr, weight_decay)\u001b[0m\n\u001b[0;32m     36\u001b[0m               (epoch + 1, 100.0*train_l_sum/n*SCALE, train_loss_sum/n, time.time() - start, n) )\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0msaveidx\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./data/HM_learn_scores_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaveidx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'saveidx' referenced before assignment"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss(reduction = 'sum')\n",
    "train(net, train_data, criterion,100, device, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './data/HM_learn_scores_' + str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\caffe2\\serialize\\inline_container.cc:209] . file not found: archive/data/1738475360880",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-06753189add9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/HM_learn_scores_2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ss20181116001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    582\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ss20181116001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    840\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ss20181116001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    832\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m             \u001b[0mload_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ss20181116001\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[1;34m(data_type, size, key, location)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m         \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\caffe2\\serialize\\inline_container.cc:209] . file not found: archive/data/1738475360880"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('./data/HM_learn_scores_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 4 1  | 0 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 1 0 4  | 0 0 0 0 0 1 1 0 0 0 0 0 \n",
      "0 0 0 2 2 1  | 0 0 0 0 1 0 1 0 0 0 0 0 \n",
      "0 0 0 2 3 0  | 0 0 0 0 1 0 0 0 0 0 0 0 \n",
      "0 0 0 3 2 0  | 0 0 0 -1 2 0 1 0 0 0 0 0 \n",
      "0 0 1 0 0 4  | 0 0 1 0 0 -1 -1 0 0 0 0 0 \n",
      "0 0 1 2 2 0  | 0 0 0 0 2 0 1 0 0 0 0 0 \n",
      "0 0 1 3 1 0  | 0 0 0 0 -1 0 0 0 0 0 0 0 \n",
      "0 0 2 2 1 0  | 0 0 1 0 0 0 0 0 0 0 0 0 \n",
      "0 0 2 3 0 0  | 0 0 1 0 0 0 0 0 0 0 0 0 \n",
      "0 0 3 0 1 1  | 0 0 0 0 1 0 1 0 0 0 0 0 \n",
      "0 0 3 0 2 0  | 0 0 0 0 -1 0 -1 0 0 0 0 0 \n",
      "0 0 3 1 0 1  | 0 -1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 3 2 0 0  | 0 0 1 0 0 0 0 0 0 0 0 0 \n",
      "0 0 4 0 0 1  | 0 -1 0 1 0 0 0 0 0 0 0 0 \n",
      "0 0 4 0 1 0  | 0 0 -1 0 0 0 0 0 0 0 0 0 \n",
      "0 0 4 1 0 0  | 0 -1 0 1 0 0 0 0 0 0 0 0 \n",
      "0 0 5 0 0 0  | 0 0 -1 0 1 0 0 0 0 0 0 0 \n",
      "0 1 0 1 3 0  | 0 -1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 1 0 2 2 0  | 0 0 0 0 1 0 0 0 0 0 0 0 \n",
      "0 1 2 0 2 0  | 0 0 0 0 -1 0 0 0 0 0 0 0 \n",
      "0 1 2 2 0 0  | 0 0 1 0 0 0 0 0 0 0 0 0 \n",
      "0 1 3 0 1 0  | 0 0 1 -1 0 0 0 0 0 0 0 0 \n",
      "0 1 3 1 0 0  | 0 0 1 0 0 0 0 0 0 0 0 0 \n",
      "0 1 4 0 0 0  | 0 1 0 -2 0 0 -1 0 0 0 0 0 \n",
      "0 2 1 0 0 2  | 0 0 -1 0 0 0 0 0 0 0 0 0 \n",
      "0 2 1 0 1 1  | 0 1 0 0 1 0 0 0 1 0 0 0 \n",
      "0 2 1 1 0 1  | 0 0 -1 0 0 0 0 0 0 0 0 0 \n",
      "0 2 1 1 1 0  | 0 0 0 0 1 0 0 0 0 0 0 0 \n",
      "0 2 2 0 0 1  | 0 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 3 0 0 1 1  | 0 0 0 0 1 0 0 0 0 0 0 0 \n",
      "0 3 0 0 2 0  | 0 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 3 0 1 1 0  | 0 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 3 0 2 0 0  | 0 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 3 1 0 0 1  | 0 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 3 1 0 1 0  | 0 1 0 -1 0 0 0 0 1 0 0 0 \n",
      "0 4 0 0 0 1  | 0 -1 1 0 0 1 0 0 0 0 0 0 \n",
      "0 4 0 0 1 0  | 0 -1 0 1 0 0 0 0 0 0 0 0 \n",
      "0 4 0 1 0 0  | 0 -1 -1 1 0 0 0 0 0 0 0 0 \n",
      "0 4 1 0 0 0  | 0 1 0 -1 0 0 0 0 0 0 0 0 \n",
      "0 5 0 0 0 0  | 0 0 0 0 1 0 0 0 0 0 0 0 \n",
      "1 0 0 0 0 4  | 0 0 0 0 0 0 1 0 0 0 0 0 \n",
      "1 0 0 1 3 0  | 0 -1 0 0 0 0 0 0 0 0 0 0 \n",
      "1 0 0 2 1 1  | 0 0 0 0 -1 0 0 0 0 0 0 0 \n",
      "1 0 0 2 2 0  | 0 0 0 0 1 0 1 0 0 0 0 0 \n",
      "1 0 0 3 1 0  | 0 0 0 0 -1 0 -1 0 0 0 0 0 \n",
      "1 0 1 1 1 1  | 0 0 0 0 0 0 0 0 1 0 -1 0 \n",
      "1 0 1 2 1 0  | 0 0 0 0 -1 0 0 0 0 0 0 0 \n",
      "1 0 2 1 1 0  | 0 0 0 0 -1 0 0 0 0 0 0 0 \n",
      "1 0 3 0 1 0  | 0 0 0 0 1 0 0 0 0 0 0 0 \n",
      "1 0 4 0 0 0  | 0 0 -1 0 0 0 -1 0 0 0 0 0 \n",
      "1 1 0 0 3 0  | 0 -1 0 0 0 0 0 0 0 0 0 0 \n",
      "1 1 1 0 1 1  | 0 1 0 0 0 -1 0 0 0 0 -1 0 \n",
      "1 1 3 0 0 0  | 0 0 0 -1 0 0 0 0 0 0 0 0 \n",
      "1 2 2 0 0 0  | 0 0 0 -1 0 0 0 0 0 0 0 0 \n",
      "1 3 0 0 1 0  | 0 0 -1 0 0 -1 -1 0 0 0 0 0 \n",
      "1 3 0 1 0 0  | 0 1 -1 0 0 -1 0 0 0 0 0 0 \n",
      "1 3 1 0 0 0  | 0 1 0 0 0 0 0 0 0 0 0 0 \n",
      "1 4 0 0 0 0  | 0 0 -1 1 0 -1 0 0 0 0 0 0 \n",
      "2 0 0 2 1 0  | 0 0 0 0 -1 0 0 0 0 0 0 0 \n",
      "2 0 1 1 1 0  | 0 0 0 0 -1 0 -1 0 0 0 0 0 \n",
      "2 3 0 0 0 0  | -1 0 0 1 0 0 0 0 0 0 0 0 \n",
      "3 0 0 0 0 2  | 0 0 0 -1 0 0 0 0 0 0 0 0 \n",
      "3 0 0 0 1 1  | 0 0 0 0 1 0 0 0 0 0 0 0 \n",
      "3 0 0 0 2 0  | 0 0 0 0 1 0 0 0 0 0 0 0 \n",
      "3 1 0 0 0 1  | 0 0 0 -1 0 0 0 0 0 0 0 0 \n",
      "3 1 1 0 0 0  | 0 0 1 0 0 0 0 0 0 0 0 0 \n",
      "3 2 0 0 0 0  | 0 0 1 1 0 0 0 0 0 0 0 0 \n",
      "4 0 0 0 0 1  | 0 0 0 0 0 1 -1 0 1 0 0 0 \n",
      "4 0 0 0 1 0  | 0 0 0 0 0 0 0 0 1 0 0 0 \n",
      "4 0 0 1 0 0  | 0 -1 -1 1 0 0 0 1 0 0 0 0 \n",
      "4 0 1 0 0 0  | 0 0 -1 1 0 0 0 0 0 0 0 0 \n",
      "4 1 0 0 0 0  | 0 -1 0 0 0 1 0 0 0 0 0 0 \n",
      "5 0 0 0 0 0  | 0 0 0 0 -1 0 0 0 0 0 0 0 \n",
      "178\n"
     ]
    }
   ],
   "source": [
    "corr = 0\n",
    "\n",
    "for x,y in train_data:\n",
    "    net.eval()\n",
    "    x,y = x.to(device),y.to(device)\n",
    "    y_hat = net(x)\n",
    "\n",
    "    hy = y.clone().detach()\n",
    "    hyh = y_hat.clone().detach()\n",
    "    \n",
    "    dh = (hy-hyh)\n",
    "    \n",
    "    flag = False\n",
    "\n",
    "    \n",
    "    for i in range(OUTPUT_SIZE):\n",
    "        if not unpack(dh[i]) == 0:\n",
    "            flag = True\n",
    "            break\n",
    "    \n",
    "    if not flag:\n",
    "        corr += 1\n",
    "        continue\n",
    "    \n",
    "    cont = \"\"\n",
    "    for a in x:\n",
    "        cont += str(int(a*5)) + \" \"\n",
    "    cont += \" | \"\n",
    "    for d in hy-hyh:\n",
    "    #for d in hyh:\n",
    "        cont += str(unpack(d)) + \" \"\n",
    "    print(cont)\n",
    "        \n",
    "print(\"{0}\".format(corr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-5e54212c5169>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "net(torch.tensor([0,0,0,0,0,5], dtype = torch.float32, device = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saveidx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-9c72818a71bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msaveidx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'saveidx' is not defined"
     ]
    }
   ],
   "source": [
    "saveidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
