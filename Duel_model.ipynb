{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import IPython as ip\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import yacht_main as yacht\n",
    "from yacht_test import create_train_set\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(torch.nn.Module):\n",
    "    \"\"\"def __init__(self, size):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.input_size = size\"\"\"\n",
    "    def forward(self, x, *args):\n",
    "        return x.view(args)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.isize = input_size\n",
    "        self.diceonly = nn.Linear(input_size, output_size)\n",
    "        self.dice1 = nn.Linear(input_size, 300)\n",
    "        self.dice2 = nn.Linear(300, 300)\n",
    "        self.dice3 = nn.Linear(300, 50)\n",
    "        \n",
    "        self.diceconv = nn.Conv2d(1, 300, (1, input_size))\n",
    "        self.convshape = Reshape()\n",
    "        self.activation = nn.LeakyReLU(0.1)\n",
    "        #self.dice4 = nn.Linear(100, 100)\n",
    "        #self.dice5 = nn.Linear(100, 100)\n",
    "        #self.dice6 = nn.Linear(100, 100)\n",
    "        self.dice7 = nn.Linear(50, output_size)\n",
    "        #self.score1 = nn.Linear(12, 12)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.convshape(x, -1, 1, 1, self.isize)\n",
    "        #x = self.diceconv(x)\n",
    "        #x = self.convshape(x, -1, 300)\n",
    "        x = self.activation(self.dice1(x))\n",
    "        x = self.activation(self.dice2(x))\n",
    "        x = self.activation(self.dice3(x))\n",
    "        #x = torch.sigmoid(self.dice4(x))\n",
    "        #x = torch.sigmoid(self.dice5(x))\n",
    "        #x = torch.sigmoid(self.dice6(x))\n",
    "        x = self.dice7(x)\n",
    "        #x = self.diceonly(x)\n",
    "        return x\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.constant_(m,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS_START = 0.9\n",
    "EPS_END = 0.5\n",
    "EPS_DECAY = 10000000\n",
    "steps_done = 0\n",
    "INPUT_SIZE = 1\n",
    "OUTPUT_SIZE = 1\n",
    "TARGET_UPDATE = 20\n",
    "TRAINSET_UPDATE = 1000\n",
    "policy_net = None\n",
    "target_net = None\n",
    "\n",
    "def select_action(state, avail):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    \"\"\"\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            policy_net(state)\n",
    "            return (policy_net(state) * avail).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(OUTPUT_SIZE)]], device=device, dtype=torch.long)\n",
    "    \"\"\"\n",
    "    if sample <= eps_threshold:\n",
    "        random_action = 0\n",
    "        randomizer = randint(1, avail.sum())\n",
    "        avail_list = torch.reshape(avail,[-1]).tolist()\n",
    "        for i in range(len(avail_list)):\n",
    "            if avail_list[i] == 1:\n",
    "                if randomizer == 1:\n",
    "                    random_action = i\n",
    "                    break\n",
    "                randomizer -= 1\n",
    "        return torch.tensor([[random_action]], device=device, dtype=torch.long)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            a = policy_net(state)\n",
    "            #a -= a.min()\n",
    "            return a.max(1)[1].view(1, 1)\n",
    "\n",
    "\n",
    "episode_scores = []\n",
    "episode_success = []\n",
    "episode_reward = []\n",
    "\n",
    "def plot_scores():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    scores_t = torch.tensor(episode_scores, dtype=torch.float)\n",
    "    success_t = torch.tensor(episode_success, dtype=torch.float)\n",
    "    reward_t = torch.tensor(episode_reward, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Score')\n",
    "    plt.plot(scores_t.numpy())\n",
    "    if len(scores_t) >= 50:\n",
    "        means = scores_t.unfold(0, 50, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(49), means))\n",
    "        plt.plot(means.numpy())\n",
    "    if len(success_t) >= 50:\n",
    "        sucm = success_t.unfold(0, 50, 1).mean(1).view(-1)\n",
    "        sucm = torch.cat((torch.zeros(49), sucm))\n",
    "        plt.plot(sucm.numpy())\n",
    "    if len(reward_t) >= 50:\n",
    "        rewm = reward_t.unfold(0, 50, 1).mean(1).view(-1)\n",
    "        rewm = torch.cat((torch.zeros(49), rewm))\n",
    "        plt.plot(rewm.numpy())\n",
    "\n",
    "    ip.display.clear_output(wait=True)\n",
    "    plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_net = True\n",
    "def init_net(isize, osize, msize, lr = 0.001, g = 0, reset = False):\n",
    "    global policy_net, target_net, optimizer, memory, EPS_START, EPS_END, EPS_DECAY, steps_done, episode_scores\n",
    "    global TARGET_UPDATE, INPUT_SIZE, OUTPUT_SIZE\n",
    "    \n",
    "    if reset:\n",
    "        INPUT_SIZE = isize\n",
    "        OUTPUT_SIZE = osize\n",
    "\n",
    "        MEMORY_SIZE = msize\n",
    "\n",
    "        TARGET_UPDATE = 5\n",
    "\n",
    "        memory = ReplayMemory(MEMORY_SIZE)\n",
    "\n",
    "        policy_net = DQN(INPUT_SIZE,OUTPUT_SIZE).to(device)\n",
    "        target_net = DQN(INPUT_SIZE,OUTPUT_SIZE).to(device)\n",
    "\n",
    "\n",
    "        EPS_START = 0.9\n",
    "        EPS_END = 0.05\n",
    "        EPS_DECAY = 1000\n",
    "        steps_done = 0\n",
    "        GAMMA = g\n",
    "\n",
    "        episode_scores = []\n",
    "        episode_success = []\n",
    "        episode_reward = []\n",
    "    \n",
    "        \n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
    "\n",
    "    #init_weights(policy_net)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0\n",
    "reward_rate = 0.1\n",
    "regul = 0\n",
    "\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    \n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1)) + torch.norm(policy_net(state_batch)) * regul\n",
    "    \"\"\"print('state ex: ' + str(state_batch[0]))\n",
    "    print('action:' + str(action_batch.view(-1)))\n",
    "    print('reward:' + str(reward_batch.view(-1)))\n",
    "    print('value:' + str(state_action_values.view(-1)))\n",
    "    print('expected:' + str(expected_state_action_values.unsqueeze(1).view(-1)))\"\"\"\n",
    "\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    #for param in policy_net.parameters():\n",
    "    #    param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    \"\"\"state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "    \n",
    "    print('after:' + str(state_action_values.view(-1)))\n",
    "    print('\\n')\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trainset():\n",
    "    print(\"Creating train set...\")\n",
    "    train_set_size = 3000 // 5\n",
    "    train_set = create_train_set(train_set_size)\n",
    "    for state, action, new_state, step_reward in train_set:\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float, device=device, requires_grad = False)\n",
    "        action_tensor = torch.tensor([[action - 31]], device=device, dtype=torch.long)\n",
    "        new_state_tensor = torch.tensor(new_state, dtype=torch.float, device=device, requires_grad = False)\n",
    "        step_reward_tensor = torch.tensor([step_reward], device=device, requires_grad = False)\n",
    "        memory.push(state_tensor.reshape(1,INPUT_SIZE), action_tensor, new_state_tensor.reshape(1,INPUT_SIZE), step_reward_tensor)\n",
    "    print(\"Created\", train_set_size * 5, \"train set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def net1_main():\n",
    "    global episode_scores, episode_success, episode_reward\n",
    "    init_net(12, 12, 1000)\n",
    "\n",
    "    num_episodes = 1000000\n",
    "    made_prob = 0.9\n",
    "    episode_scores = []\n",
    "    \n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "        reward_total = 0\n",
    "        yacht.reset_game()\n",
    "        state, score, _, avail = yacht.get_yacht_output()\n",
    "        state = torch.tensor(state[:12], dtype=torch.float, device=device, requires_grad = False)\n",
    "        for t in count():\n",
    "            avail = avail[31:]\n",
    "            avail = torch.tensor(avail, dtype=torch.float, device=device, requires_grad = False)\n",
    "            action = select_action(state.reshape(1,INPUT_SIZE), avail) + 31\n",
    "            reward = yacht.update(action)\n",
    "            if reward != -1:\n",
    "                reward_total+=reward\n",
    "\n",
    "            new_state, _, done, avail = yacht.get_yacht_output()\n",
    "            step_reward = torch.tensor([reward], device=device, requires_grad = False)\n",
    "            \n",
    "            #print(str(action) + ' ' + str(reward) + ' ' + str(yacht.dice_status))\n",
    "            \n",
    "            if random.random() < made_prob:\n",
    "                yacht.handled_roll()\n",
    "\n",
    "            if not done:\n",
    "                new_state = torch.tensor(new_state[:12], dtype=torch.float, device=device, requires_grad = False)\n",
    "                memory.push(state.reshape(1,INPUT_SIZE), action - 31, new_state.reshape(1,INPUT_SIZE), \\\n",
    "                        step_reward)\n",
    "            else:\n",
    "                new_state = None\n",
    "                memory.push(state.reshape(1,INPUT_SIZE), action - 31, None, \\\n",
    "                        step_reward)\n",
    "\n",
    "            state = new_state\n",
    "\n",
    "            optimize_model()\n",
    "            if done:\n",
    "                state, score, _, _ = yacht.get_yacht_output()\n",
    "                episode_success.append(state[:12].count(-1) * 10)\n",
    "                episode_scores.append(score)\n",
    "                episode_reward.append(reward_total * 10)\n",
    "                \n",
    "                #print(\"{0}) {1}\\tscore : {2}, turns = {3}\".format(i_episode, state[:12], score, t+1))\n",
    "\n",
    "                if i_episode % 200 == 0:\n",
    "                    plot_scores()\n",
    "\n",
    "                break\n",
    "        #if i_episode % TRAINSET_UPDATE == 0:\n",
    "        #    add_trainset()\n",
    "        if i_episode % TARGET_UPDATE == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        if i_episode % 10000 == 0:\n",
    "            torch.save(policy_net.state_dict(), './data/net1/net_' + str(i_episode//10000))\n",
    "\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def net2_main(net1_name):\n",
    "    global episode_scores, episode_success\n",
    "    init_net(20, 32, 3000)\n",
    "    \n",
    "    reward_net = DQN(20, 12).to(device)\n",
    "    reward_net.load_state_dict(torch.load('./data/net1/' + net1_name))\n",
    "    reward_net.eval()\n",
    "    reward_net.requires_grad = False\n",
    "    \n",
    "    num_episodes = 500000\n",
    "    made_prob = 0.66\n",
    "    episode_scores = []\n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "        yacht.reset_game()\n",
    "        state, score, _, avail = yacht.get_yacht_output()\n",
    "        state = torch.tensor(state, dtype=torch.float, device=device, requires_grad = False)\n",
    "        for t in count():\n",
    "            avail = torch.tensor(avail, dtype=torch.float, device=device, requires_grad = False)\n",
    "            action = select_action(state.reshape(1,INPUT_SIZE), avail)\n",
    "            \n",
    "            if action >= 31:\n",
    "                a = policy_net(state)\n",
    "                a -= a.min()\n",
    "                action = (a * avail[31:]).max(1)[1].view(1, 1)\n",
    "            yacht.update(action)\n",
    "\n",
    "            new_state, _, done, avail = yacht.get_yacht_output()\n",
    "            step_reward = reward_net(state).max(1)[0]\n",
    "\n",
    "\n",
    "            if not done:\n",
    "                new_state = torch.tensor(new_state, dtype=torch.float, device=device, requires_grad = False)\n",
    "                memory.push(state.reshape(1,INPUT_SIZE), action, new_state.reshape(1,INPUT_SIZE), \\\n",
    "                        step_reward)\n",
    "            else:\n",
    "                new_state = None\n",
    "                memory.push(state.reshape(1,INPUT_SIZE), action, None, \\\n",
    "                        step_reward)\n",
    "\n",
    "            state = new_state\n",
    "\n",
    "            optimize_model()\n",
    "            if done:\n",
    "                state, score, _, _ = yacht.get_yacht_output()\n",
    "                episode_scores.append(score)\n",
    "                if i_episode % 200 == 0:\n",
    "                    plot_scores()\n",
    "\n",
    "                break\n",
    "\n",
    "        if i_episode % TARGET_UPDATE == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        if i_episode % 10000 == 0:\n",
    "            torch.save(policy_net.state_dict(), './data/net2/net_' + str(i_episode//10000))\n",
    "\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def net3_main(lr, g):\n",
    "    global episode_scores, episode_success, reset_net\n",
    "    init_net(20, 43, 10000, lr=lr, g=g,reset = reset_net)\n",
    "    reset_net = False\n",
    "    \n",
    "    num_episodes = 50000\n",
    "    num_average = 5\n",
    "    num_optimize = 5\n",
    "    \n",
    "    for i_episode in range(num_episodes):\n",
    "        \n",
    "        episode_memory = []\n",
    "        episode_total = 0\n",
    "        episode_suctotal = 0\n",
    "        for i_average in range(num_average):\n",
    "            yacht.reset_game()\n",
    "            state, score, _, avail = yacht.get_yacht_output()\n",
    "            state = torch.tensor(state, dtype=torch.float, device=device, requires_grad = False)\n",
    "            for t in count():\n",
    "                avail = torch.tensor(avail, dtype=torch.float, device=device, requires_grad = False)\n",
    "                action = select_action(state.reshape(1,INPUT_SIZE), avail)\n",
    "\n",
    "                reward = yacht.update(action)\n",
    "                reward = torch.tensor([reward], device=device, requires_grad = False)\n",
    "\n",
    "                new_state, _, done, avail = yacht.get_yacht_output()\n",
    "\n",
    "                if not done:\n",
    "                    new_state = torch.tensor(new_state, dtype=torch.float, device=device, requires_grad = False)\n",
    "                    episode_memory.append(Transition(state.reshape(1,INPUT_SIZE), action, new_state.reshape(1,INPUT_SIZE), \\\n",
    "                            0))\n",
    "                    state = new_state\n",
    "                else:\n",
    "                    new_state = None\n",
    "                    if reward == -10:\n",
    "                        memory.push(state.reshape(1,INPUT_SIZE), action, None, reward)\n",
    "                    else:\n",
    "                        episode_memory.append(Transition(state.reshape(1,INPUT_SIZE), action, None, 0))                \n",
    "                    state, score, _, _ = yacht.get_yacht_output()\n",
    "                    episode_suctotal += state[:12].count(-1) * 10\n",
    "                    episode_total += score\n",
    "                    break;\n",
    "        \n",
    "        average_reward = episode_total / len(episode_memory)\n",
    "        average_reward = torch.tensor([average_reward], device=device, requires_grad = False)\n",
    "        for x in episode_memory:\n",
    "            memory.push(x.state, x.action, x.next_state, average_reward)\n",
    "        \n",
    "        for i_average in range(num_optimize):\n",
    "            optimize_model()\n",
    "        \n",
    "        \n",
    "        episode_success.append(episode_suctotal/num_average)\n",
    "        episode_scores.append(episode_total/num_average)\n",
    "        if i_episode % 50 == 0:\n",
    "            plot_scores()\n",
    "        #if i_episode % TARGET_UPDATE == 0:\n",
    "        #    target_net.load_state_dict(policy_net.state_dict())\n",
    "        if i_episode % 1000 == 0:\n",
    "            torch.save(policy_net.state_dict(), './data/net3/net_' + str(i_episode//1000))\n",
    "\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def net4_main():\n",
    "    global episode_scores, episode_success\n",
    "    init_net(12, 12, 10000)\n",
    "    \n",
    "    num_episodes = 50000\n",
    "    num_average = 5\n",
    "    num_optimize = 50\n",
    "    made_prob = 0.85\n",
    "    episode_scores = []\n",
    "    episode_success = []\n",
    "    \n",
    "    for i_episode in range(num_episodes):\n",
    "        \n",
    "        episode_memory = []\n",
    "        episode_total = 0\n",
    "        episode_suctotal = 0\n",
    "        for i_average in range(num_average):\n",
    "            \n",
    "            yacht.reset_game()\n",
    "            state, score, _, avail = yacht.get_yacht_output()\n",
    "            state = torch.tensor(state[:12], dtype=torch.float, device=device, requires_grad = False)\n",
    "            for t in count():\n",
    "                avail = avail[31:]\n",
    "                avail = torch.tensor(avail, dtype=torch.float, device=device, requires_grad = False)\n",
    "                action = select_action(state.reshape(1,INPUT_SIZE), avail) + 31\n",
    "                reward = yacht.update(action)\n",
    "                reward = torch.tensor([reward], device=device, requires_grad = False)\n",
    "\n",
    "                new_state, _, done, avail = yacht.get_yacht_output()\n",
    "                new_state = new_state[:12]\n",
    "\n",
    "                if random.random() < made_prob:\n",
    "                    yacht.handled_roll()       \n",
    "                \n",
    "                if not done:\n",
    "                    new_state = torch.tensor(new_state, dtype=torch.float, device=device, requires_grad = False)\n",
    "                    episode_memory.append(Transition(state.reshape(1,INPUT_SIZE), action - 31, new_state.reshape(1,INPUT_SIZE), \\\n",
    "                            0))\n",
    "                    state = new_state\n",
    "                else:\n",
    "                    new_state = None\n",
    "                    if reward == -10:\n",
    "                        memory.push(state.reshape(1,INPUT_SIZE), action - 31, None, reward)\n",
    "                    else:\n",
    "                        episode_memory.append(Transition(state.reshape(1,INPUT_SIZE), action - 31, None, 0))                \n",
    "                    state, score, _, _ = yacht.get_yacht_output()\n",
    "                    episode_suctotal += state[:12].count(-1) * 10\n",
    "                    episode_total += score\n",
    "                    break;\n",
    "        \n",
    "        average_reward = episode_total / len(episode_memory)\n",
    "        average_reward = torch.tensor([average_reward], device=device, requires_grad = False)\n",
    "        for x in episode_memory:\n",
    "            memory.push(x.state, x.action, x.next_state, average_reward)\n",
    "        \n",
    "        for i_average in range(num_optimize):\n",
    "            optimize_model()\n",
    "        \n",
    "        \n",
    "        episode_success.append(episode_suctotal/num_average)\n",
    "        episode_scores.append(episode_total/num_average)\n",
    "        if i_episode % 50 == 0:\n",
    "            plot_scores()\n",
    "        #if i_episode % TARGET_UPDATE == 0:\n",
    "        #    target_net.load_state_dict(policy_net.state_dict())\n",
    "        if i_episode % 1000 == 0:\n",
    "            torch.save(policy_net.state_dict(), './data/net4/net_' + str(i_episode//1000))\n",
    "\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = DQN(20, 12)\n",
    "net2 = DQN(20, 32)\n",
    "def duel_action(state):\n",
    "    action = net2(torch.tensor(state, dtype=torch.float, requires_grad = False).reshape(1, 45)).max(1)[1]\n",
    "\n",
    "    if action == 31:\n",
    "        action = net1(torch.tensor(state, dtype=torch.float, requires_grad = False).reshape(1, 45)).max(1)[1]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(net1r,net2r):\n",
    "    net1 = DQN(20, 12)\n",
    "    net1.load_state_dict(torch.load('./data/net1/' + net1r))\n",
    "    net1.eval()\n",
    "    net2 = DQN(20, 32)\n",
    "    net2.load_state_dict(torch.load('./data/net2/' + net2r))\n",
    "    net2.eval()\n",
    "    \n",
    "    yacht.reset_game()\n",
    "    done = False\n",
    "    while not done :\n",
    "        state,reward,done,_ = yacht.get_yacht_output()\n",
    "        print(state)\n",
    "        action = duel_action(state)\n",
    "        yacht.update(action)\n",
    "        print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net1(net1r):\n",
    "    net1 = DQN(20, 12)\n",
    "    net1.load_state_dict(torch.load('./data/net1/' + net1r))\n",
    "    net1.eval()\n",
    "    \n",
    "    yacht.reset_game()\n",
    "    done = False\n",
    "    while not done :\n",
    "        yacht.handled_roll()\n",
    "        state,reward,done,_ = yacht.get_yacht_output()\n",
    "        print(state)\n",
    "        action = net1(torch.tensor(state, dtype=torch.float, requires_grad = False).reshape(1, 45)).max(1)[1] + 31\n",
    "        yacht.update(action)\n",
    "        print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3hUxdrAf7MtCb2FXkIHFUEFBAuCqGD3Wq6IXfywXywXRSxwsXHtvWADC6KoF1AEQQQBUTRI7y3SIXQI7GazO98fW7Ll7GY32d0E9v09D0/OmTPnnNkNmXfmrUprjSAIgiAAmMp7AIIgCELFQYSCIAiC4EeEgiAIguBHhIIgCILgR4SCIAiC4EeEgiAIguBHhIIgxIFSaopS6uZE9xWEioKSOAXheEcpdTjgtBLgAFze8zu01p+nflSCUDERoSCkFUqpPOB2rfVPBtcsWuui1I9KECoOoj4S0halVE+l1Bal1CNKqR3Ax0qpmkqp75VS+Uqpfd7jxgH3zFJK3e49vkUpNVcp9aK370al1IWl7NtcKTVbKXVIKfWTUuotpdRnKfw6BAEQoSAI9YFaQDNgIJ6/iY+9502Bo8CbUe4/HVgN1AGeBz5USqlS9B0L/AHUBoYDN5b6EwlCGRChIKQ7bmCY1tqhtT6qtd6jtf5Ga31Ea30IeAY4J8r9f2ut39dau4AxQAOgXjx9lVJNgS7Ak1rrQq31XGBSoj6gIMSDCAUh3cnXWtt9J0qpSkqp95RSfyulDgKzgRpKKXOE+3f4DrTWR7yHVeLs2xDYG9AGsDnOzyEICUGEgpDuhHpaPAS0BU7XWlcDenjbI6mEEsF2oJZSqlJAW5Mkvk8QIiJCQRCCqYrHjrBfKVULGJbsF2qt/wZygeFKKZtSqjtwabLfKwhGiFAQhGBeBbKA3cDvwNQUvfd6oDuwB3ga+BJPPAXgibVQSp3tPT47MPZCKTVUKTUlReMUjnMkTkEQKiBKqS+BVVrrpO9UBCEQ2SkIQgVAKdVFKdVSKWVSSvUFLgcmlPe4hPTDUt4DEAQB8MRLfIsnTmELcJfWemH5DklIR0R9JAiCIPgR9ZEgCILg55hWH9WpU0fn5OSU9zAEQRCOKRYsWLBba51tdO2YFgo5OTnk5uaW9zAEQRCOKZRSf0e6JuojQRAEwY8IBUEQBMGPCAVBEATBjwgFQRAEwY8IBUEQBMGPCAVBEATBjwgFQRAEwY8IBUEQUkqRy81XuZtxuyXFTkVEhIIgCCnlg7kbefjrJYxfULErjjpdbvYWFJb3MFKOCAVBEFLKnsOe2kEHjjrLeSTR+ff4xZz61PS029EkTSgopT5SSu1SSi0LaHtBKbVKKbVEKfU/pVSNgGuPKqXWKaVWK6X6JGtcgiAIsfDd4m1AeBHv451k7hRGA31D2qYDJ2mtTwbWAI8CKKVOAPoBJ3rveVspZU7i2ARBKCckW3/FJmlCQWs9G9gb0jZNa13kPf0daOw9vhwYp7V2aK03AuuArskamyAI5Y9ClfcQBAPK06ZwG+ArNt4ICLQ6bfG2haGUGqiUylVK5ebn5yd5iIIgpCvpuqEpF6GglHoMKAI+9zUZdDP8nWitR2mtO2utO2dnG6YDFwShAlPRJ9s5a/M5Wujyn6diPzN9xU7GzMtLwZtKJuVCQSl1M3AJcL0urgW6BWgS0K0xsC3VYxOEisQfG/eSM2QyC/7eW3LnYxBVAbVHG/IPc+OHfzD0f0tT+t7/+ySXYZOWp/SdkUipUFBK9QUeAS7TWh8JuDQJ6KeUylBKNQdaA3+kcmyCUNGYs9ajHv113Z5yHkn6cNjhMXmu23W4XMdQnm6wyXRJ/QL4DWirlNqilBoAvAlUBaYrpRYppd4F0FovB74CVgBTgXu01q4IjxYE4RijwFHEV39uRmudEO+jQ3YndmfypghNYsYZL0cKizhp2I88N2Vl6l/uJWnlOLXW1xk0fxil/zPAM8kajyAkm+XbDrDrkINebeuW6zicLjf7CgqpWy0zIc+zO10cdhRRp0pGqZ8xfNJyxi/YQtPaldAJsCp0GD6NBtUz+e3R3mV+ViDl7RF12O7ZqUxYtI3HLj6hXMYgEc2CkCAufn0ut378Z3kPg8f+t5Suz86gwFFUcucYaPfEVDo//VOZnpHvjWIOMuAqxb6CwlKnkth+wF6mMUUjnl3Cul2H+favLUkbS6oRoSCkBVpr3pq5zp9iIVXkH3Kw61DyJi8jvsr1TFCv/7w2qN3udLE+PzZd+bpdh/h8fsTa7qUmdJdwylPTOfWp6Ql/T2kpjfH7vJd/4cGvFid0HOUZ4CdCQUgL/ti4lxd+XM0j36TWq6TLMz/R9ZkZKX2nj7/+3hd0/uBXi+j90i8cKSx5B3Hha3N47H/LSuwXK4FzbawT3rKtB/jkt7yY35G3u8Bw17F6x6G4d03lNilHEEpf/bmZnCGTcRQl39QqQkFIC4q83hyxTIjHC6ET5Ny1uwHPBFMSTldiZ0XlXYIHTrYlLcoveWMuT06M3U2z54uz6PnCzKA2p8tNn1dnc+dnC/xtk5dsJ2fI5GMqA+oL01YDcOBI8pMIilAQ0oJUrvxOe2o6N344P6jt2R9WsnbnodQNgmD9fSDDv1uR0nFAsQBI9u/hoD1Y6Lu8i4H5G4tjPUbP2wh4bAFb9h0hZ8hkpi3fEXSfjnCcOorfunDTPvYfSZ0AE6EgpBWpCJjaU1DIHO+q3Meo2Ru48cPShd68PH0Nuw6mxi7hdmv/RFoW9hUUcu/YvzhkD17ZFrk1Ok7JUORyx3VPrCqWt2et49I35gLw7V9b2XHAzsLN+wHiHmOiMPJ++sfb8xK+c4uGCAVBSBFlccXcuLugFO8LRsUgEf/x9q+0HPpD3O8K5Z1f1vP9ku2Mnb/J+25P+52fLWDMb38HtZVEq8em8O4vGyhyucNiE4yM+M9PXe0/9s3tpoB3+VSJs1bnsy9AHXPuS7N4YoLHjrJqR+J2det2Hea20X8mJK5CAxMXbcXpcpd9YBEQoSCkBYnwjS/zGFI8hMD3HTjixB1lAAeOOLn8rV9ZvOVAmd550O6kKGDCOmh3Mmlx2TPW/HfqKs7670zaPTE1qP3qd34L67t57xHmrM0nb3eB//ceuAJfuGl/2D0azZEI6jaA92dv4NkfogeURYqCHjZpGT+v2kVu3j7D64cNjOCRflWTl2xn0LhFdH8uec4LSQteE4SKiNOl+eS3PK4/vRlmU8VLvrOvoJAsm5lMa9nLiWg0L09fQ97uAsOJefm2A9zz+V+0zK7Cgk372G9gxFy3K74V88nDp3FZx4bUr+4JnHtr5noAWtetEtY38NvP211ATp3KUZ+9w0CFtmnvEYOe+FV184acC8BRp4tlWw+wo5SxDc94BcLQi9pH7PP7hj3c+dkCJt5zJpUzYp9a564tzvZc0u7JZ1vYfbiQ92dv4P96tIj5PbEiQkFIK/7YuJc/Nu7FajZxXdemKX337sMOChxFUSeMU56azmnNavLNXWcEtWtgxwE7NSpZowqMGSt3Bp2/PmOtYb+Zq3Zx62hPoF3eHuOJFeC8l2dHvBaJSYu3ceWpwZnvC0tQd7w3ewNt6lXhh6XbGX/nGVH7hrJo836WbCle/W/Zd9R/fMbIn/3Hl3jtB0YkYhf336mrOGQvYtHm/ZzZqg4AP63YydI4dl9HHLGrmOau250UoSDqI6FM2J0uXp+xlsKi5Ok4E0HoH/1he+pdU93aE+hUEgv+3hdm7NUauj03gzs+XRDhLg+BLpw7D0YO1FtSBjXRTR/9wbCJy5i4aCvLtho/59u/tgad/20geEJtHP/5bgV/RlCxROOKt34N+twrth+M+xnRiPf/ysbdBf6/h9s/yfV7RN0Q4pHmdnsCKgM9pi5+Yw7gcVYoyQaRLKcJEQpCmfhgzgZenr4mriCjRPDTip3MXL0rpe9MBLGmZnhp2mrD9l/W5HPNu/PKPI5o9oWSmL0mnzG//c2gcYuirr6PJaJ9Gz1fDI590FqzZMv+cA8l7+njE5bR5vEp7C4hev7d2et54cfVPPz1En/boQABMWjcwpjGnmhEKAhl4qh3NVNWz4oP5mzgj417afHoZP7YGF4/YOGmfUG7kds/yY0rz1DoH72jyMXizcEGx237j/LCj6tickd875f1rPSuSB+fsJScIZNjHouP3Ly9EVMkLwiJRg40lEdbTcfqTvrOrPUx9QukKIkeL4Gr3qe+X5GSyN1Y2Rdia5m0eBuXvfkr3y/ZHvW+wMk+lJmrdwV5SRkxa3X0ypLJsoiJUEhT/t5TQM6Qyf6c/cni51U7+eKPTThdbp6cuIz8Q8arp6cnr+Sf7/2GW8M/3wv2KFm36xD/eHue3/vj0W8j/7HFyovT1nD5W7+ydX+x/nnQuIW8NXM9SyOoRAJ5bsoqLnxtDjlDJvPZ75vifv/UZTu4+t3faBHF/bM0i3kjY6wRJen4jXhp+pq474lGpN3Kh3M30vbxqYbXksX0FTtL7uRlvdfLKNR4fyjEi8goer7V0B84+/mfY1rQOIrc/Lpud8TrsbgYlwYRCkmksMjNzFXJUXF8+ecmcoZMZs9hB1prZqzcGddKzrfa/N/CrSX0LBu3jc7l0W+XMmPlTj757W+GTYo/n86ewx6PixXbPCvzL/4oTtPw4/Id5AyZzKYoxtJoHLI70Vrjdmv/TsRosV3kcocZcUsiWhRqYNqFSFQEN9pAVm0/yF0G4/5gzgb2FhTGvVt675cN/uN4prfHUlwVLRLTV+xkQpS/H6P/k0Vuzea9Rw16G3P9B/MjXpOdwjHIyCmruHX0n0kppzjWOzFu2nuEGSt3MWBMLu/+Er9KIFGUtKr1TbSJ9tX3/VEu2bo/qsohmkro/TkbaDH0B7/Bz6jvGz+vY8CY3LjsGDd/FFsE86LN4X7zUOzO6RlU8LVAdZ3WGrvTlVT1jo8py3aEtT09eWVE19BoBO5qflwe/txIfD4//p1ZonAUuYJ+Ffd/uShi321JTO0NYmg+Jvl7jycKdV9BcpNY+XLVG61Adh2yx73Cnbhoa0w1aj3P9kySBVECfwJxubU/WEdrzUF7yd/NvPXF5SgjBQg9/PWSUqkcFIovvQniIqm2wBMQBbD3cOw5aFZuj83H/4q3fg0fV8gffKiY+k9A/qJRszfQ7omptHpsSsxjKw2HkuixtTuO77U8afv4VDaUIrr8WEKEQgj/W7gl4cmntu4/yqTF27htdOILsGiibyP7jfqdAWNy/avIA0ecYSvqRZv3Bxk2B41b5E9PEKmP79m+dAC+XcrERVvJP+RRaQU+w7f4nrZiJycN+5HCIjcfzNnIycOn8UYEX3ofr/muK3jxx2DjnO+5RtGoewsKS1w9u7X2u276vsdoKoF4iKS3j8WQXdJCItAW8tyUVfENrJTk/h3ZwJ2ogj7HApNLMDAnkz/yirUOybIpSPBaABt3F/DAl4s5u3UdPh1weqmecaSwiKOFLmoHlC4cNin29L+xYvTfYeOe8BXMhvzgto4jptG1eS2uPrUx4NGL+nzK80ZeHPF9vtVs3siLOXDEiTKF+56v3nGIQeMWcXLj6tzbq1XU3cb4BZv56FdPtkojA+bMVbs4aHdyeafiICitdZiePZLe3e50+Yu3nN68Fpd2bGjY78LX5hSfeL/UMb/9zX8uPynkPR52HLTzzYKyVdn6MobU1atTnFG1rETTfQuJ4/cNAUIhSe8QoRCAbwW9K0rQT0lc8sZcNuQXRJ1gE41vwWDkyukjcOr8Y+NeLjihHhCsEhj6v6UcPFqyOqfjiGkAYWkibv3Yo0NfsuUABSXULSipgIsv2jZQKChUmE3ix+XGqjFHgPvq/I17g1Inx8LW/UepXdkWFj38wo/R3Qhj4dcAdVggkVJdg0y6QjhiUzhGCF2ZG7HroD2q/jqQU0ZM46O5GyNe35hfEDSZ5AyZbGgMjcXAO3b+phJ9r6MRTS+8YnvZEq2BZ+s8LQ7XwXgJFJBnjvyZAWOSU2/5O4M8ROP+2ET7J2O3icxek0+roT9U+EhyIXnEkz4jHkQoJIAOw340jECNJMm7PjuDLs/EVgh93xEnI74PL4rie/ZD4xeHFU0x8oFOiXujCjwM/vBBnjQpIBGrqF/X7eG5H1aG1QRIBkO+jd/NssitIxreheOfZHk3iVBIAIccRbzx87q47/tr076oKoOyksxnQ/J0mmXhlzWeYLxEje292RsYOSW2KOfy4KLX55TcSRDiIGlCQSn1kVJql1JqWUBbLaXUdKXUWu/PmgHXHlVKrVNKrVZK9UnWuGIhVUFDV749j3+PX2x4bddBe9D2MJJaKBp7CiKrqGJ1l9RaB733yYmRbQGBJobZaxITKR1vTWVfbEAiPTPK0y9eEFJNMncKo4G+IW1DgBla69bADO85SqkTgH7Aid573lZKlT2hfJwYlcJLNj+v2mVoIO754iwufTM42dh3i4p10SWN1O50+WMIwGNT+GFpsb3gm79i86CZtHhbkDrqE2/VLCiuYFX8zmL99rcJcuscHCV/TDTemRX/zi0aExaVvVCMIBwLJE0oaK1nA6Gz3eXAGO/xGOCKgPZxWmuH1nojsA7omqyxVSSOOl1huX7A2O8+nv3LU9+vCHKF/W3DHu7+/K+4x1faoiSJYk0pyyJ+GiC8BEGInVTbFOpprbcDeH/W9bY3AgKdt7d428JQSg1USuUqpXLz85ObzK0s5AyZXCpf870FiQmcC1V5fP576SbJ8g5KWltKQ2qyAnsE4Xinohiajf6CDRfGWutRWuvOWuvO2dnZSR5W2TBKOxEttfGSLfs59anpPDclci1Yu9PF3oLCuCe9n1aWLjHfwXIoRlNWCovcSfPhFoTjnVQHr+1USjXQWm9XSjUAfDPVFqBJQL/GQLkpcZPpaPL1AuNo1g/mbODpyR5hEJg9MhCtNf1G/c6izfs5rVlNwz6JJjS1xbHAvWP/qpCeUYJwLJDqncIk4Gbv8c3AxID2fkqpDKVUc6A1EFuKyQSSitXlI98Y+6P7BEI0Vu045M+oWZbKWbEyc/WumGoLVDSSGeAmCMc7SdspKKW+AHoCdZRSW4BhwEjgK6XUAGATcA2A1nq5UuorYAVQBNyjta44pZeisCE/dcFDqwKMrgs3GadbTiSlNfJWBMSmIAilI2lCQWt9XYRLvSP0fwZ4JlnjSRa7AtJVVKQSgulOogz2gpBuVBRDc7nz2/o9hnWGOz/9E7d8HJsmy5dt9Hjh/TmRcy4JgnB8IllS8aiArnv/dzo2qRF2bfdhR9QC2oFKiliLph8r7D5c+myxgiAcm8hOATjgTRe91htXEOvUvnjzfh4IKMeXrHrMgiAIqUJ2CgHEa5oc+Gmuv2oXwAwRCoIgHOPITiGA0B3CZ6WMAhYEQThWEaFAZPfFxycUZwTNGTKZT3//G601H83dyKodB1M1PEEQhJQh6qMIfL8kPKD6iQnLyLKa/UVv6lXLCOsjCIJwLCM7hQB8mUl3HLAzPCDDaCB/bSpO+1BB664IgiCUGhEKgCMkPuFwlMygm/Yc8R8bxTUIwrHCA5avycvsj4VjL+lhOlOZo9QgedkG0lYo9BjXg4+WfQTAtaN+j/m+uet2J2tIgpBSBlm+BaCpEq85gErY6aJWlfcwSuSXjAdYlHlH0p6ftkJhn2Mfryx4JUqPkh1Uj8W00oIQSkO1p7yHEBM1OUh1inONZVCINYG7nBWZtzE+YwT1wmqDVSzqqOQ6uaStUCiJfUckd46QHjxj+bC8hxATCzPvZHHmQP/56sxb+C3j3lI+TXOR6XfMhKuALzLPL+Uzjw9EKETgeEtZIVQsTLh5wvIp9Un8Kt2Mi+Zqe8Tr1ThMH1NxPq9mpmD1UQu1jVaq5BretTnAmabgVPDXmGdxosqLb8Ax0FgZp5rxrZqrURD0mUdYPiYvsz/f2YbSUa3jR9vDZFC80LvINJ+3ba9zh/k7WqstVKHYVhioTmurNpGX2d9/bxe1ym+Daa22cI15Vpk+V0u1laUZAxht/S95mf0Nv7tmageVSF1ZXBEKgpACrBTR27TAf97VtIoBlik8bx2V8HcNtnzJzIyHDCdSG06WZA7kPdurhvdm4uDnjH/zU8bD/raFGQOZanvEf97DtJi8zP4syLyLz23PBd3/gnUUkzOGAnCreQp5mf25zPRrmT9TU1VcI6MmB4PURk3VTpZk/h8zMx4C4BLTb9xkmQ5AB1MeEzOepK1pC0MsX9DDtJjZtkG8bXsdgN7mhUzPeJjRtucDvoNi4fFjxhAAptsG09O0iPEZI/i3ZTx1OMD0jId5Iej3p3nN+ib/sXxMF7WKlmor1QLUXSbcnGFaFtT/B9ujVFVH6WleDMDkjKGcqtaQl9mf5Rm3AvBLxoOsyLwt7DsJFGSJRISCIKSAhy3j+ND2kt+Qqbzx8zaVGJ14T9NC/msZBWi6mTwFm7Lx1Nw4Ra2lm8kTWxM44RnxpvX1sLaa6jDtTMUVAz+x/Tfo+vmm3KDJD2Cg+TuGWT8F4HXbW9xgnh71vWOsI5lheyhoNe/jZLWesbZn/ecLM+9kbeZN/vPZGQ/4j1+0vsubtjcM33Gr5Uc+sf2XpqZiYXmaaS0AnU1r/G3XWWZymWlekFdWU1O+X3C0VlvIzbzLf+05y/sAPGb5nMvN87jZMp3xGSOYkTGYJZkDqUYBeZn9mZ9xN2Ntz/K85T0AnrZ8RIbB7//bjOEAVFYOsqLsEIZaxka8VhYkeE0QUoBPtVFNFYAGt/asx6oQXse7NIy2vQDA7+72uLxrPRNuAP6XMQyAHPtY6qro5VXPMy+Mer024ZX43re9DMB6dwN/21DrF0F9nrZ+zJeuXlTmKPdYJvKNqwerdBNuMk9jsqsb55iXAPC57Vn6Fz5GIVbAs3OZlPFE1DEFcrV5dsx9o/G67U1y7eECEqASwdmDr7PM5DrLzIjP+sUrtLK9qq5/Wn7Bqor4h7nkHVSzAFXW3eYJvO26wn9+mXleifeXBhEKggA0Ip89VMNOYqPUT1R5mHBj8U7QVq9h02exOsmUV+Z3DLeM9h+/YnuHle6mAJhxB6287zZP5GHrlzE/Ny+zf9C5CTf9zTMi9m9pimzHABhvG04nk6f++P9ZfmCPrkptdYgR1jH+Pp1Na1iT6anYe2vhYHqZFhk+KxXMy/yXYXt384q4nlNThVdnjEUgAEz1qq8AHrZ+xXLd3H9eRSXHziBCQRDQ/Jo5CPCspn1ksw8nFvZT1d9WmaMUkBXzk3369aXuHADetb1Kjn0sOu6cvMbUZR+3WKYFtbU3bfKMVdkZYy1W9UQTCC9a38Wlo2uT/2MZzY2Wn0o9Vp9A8FFbRQ/A+ti7+xGK+Zc3tiSZiE1BKBP9zD8z1PJ5yt9bjcO0U5sS8ixbiK+7hSKqcoQ/M+8JChI6x7SY5ZkD2JBxvV/ffIHpz5gMfh0CdgQKNxbl2TH4VvWl5Umv3t6IfuaZfvtCSVxtns21lllR+5RFIAiJYbeunvR3iFAQysRI6wcMtEyOuX/nAJe+QJqr7SUEImnyMvsz0PwdAF/angraWpeFrAAd8Te2YbxlfZ2lmbeH9bvE9BsAJqW5zzKBM0zLGGV7xe/14qOTWsf5ptww9YuP1Rk384XtGe+nirxjaKx2cZHJE21fhwPMtg2ipSou+dpSbeUSc+Ro/D7m3IjXhGOTVPxORX0kJJV/mb/lQevX5NjH0kFt4OuMEXzvOp17nYP8fX62PUgL0w7WuhtxXeHj7KY6yquDz8BJJ9N6xtmeBjwGzFGuS2nv9YbJxBGTHSCb/TiwcogsdMha6BzTYv+xzxvFiPW6of/4NvMUGuJJeZKtDnCKWstC3ZqaHGRCxpNRx2JTxQFTJ5gi1+z4zvY4NdVh/nL/wKmmdQDMyBjMhY7nuMo8mxvNsnIXEo/sFIQEYRzs96D1a/9xHeXxXLnEPJ9HLZ+To7ZThwO0MO0AoLVpK7mZd3GhaT4bM2/gK9sIVmXe6hcIPkZZX/IfN1Kx5aL6M/NulmT+H6Os4alNjsYgVGpykNMDVDFV1VGusRR7uvwvYxh5mf1ZmHlnTOMJ5EvbCO+R9gdcQbGB0icQfEzJeJTbLVPIUM6435VKrnZEF46J5GXn1Sl7VyLZ5M4OsmNVBEQoHOPkZfYPUlMMME/mVOXxue6k1lHHwIUwXq4xz6IRxhGlPrJC3PSAoChMMy7s2Pznd1gmMyvjIfqZfw677x3bawB0CfAdD+QCc3EQWEe1PvrggT6mP/3H5wfc62O/rlLCEzQLM++kl3lxCf1Kx+mmVVxk+p07vaqxDqa8hOb0STV9HCO5q3AQubpdUt8zzHmz//g39wlh1ze5sxPynt6O6AbvL4t6hrX94OrKdYWPRb3v7aLL6FH4WqnH9VrRP0p9bzTKRSgopR5QSi1XSi1TSn2hlMpUStVSSk1XSq31/qxZHmM71nnC+rk/+GVCxpNMCPHx/iPjbsMApUhkUMgL1lH+1XpLtZU7vJNXIO9bXyITBy9b3/b7sgcaoCtzlB6mJWH3ucvohVNAFhsyrqdtFKPze7bg3UEGhVThCONtw8nCzviMERHu9FCDcJfCRPO27XWGWMf5z7ubjOt5lBaHTqymuI9jJA8VGu+K8nUNprhPj+t5txYOpq19tP88190mav8c++eMcfXxn68LUO3luesBRJ1w7drKLYWDw9oHFD5ET8dLQW3rdSM6298J6/uU83o629/hkaKBYdfudt7Pb+4Tg3YB5zue51bvO28pfJjni/r5r21yZzOm6Hw62kdxkePZoGe5tPHfyCtF10T8fGUh5TYFpVQj4F/ACVrro0qpr4B+wAnADK31SKXUEGAI8EiUR6U9V5t/CTr3BSsBfp184wD1ymfWZ6ir9nOJ+XfudRr7YIdi9j7HF/T0te0/1FSHGe3qQ6eAVfpZ5uXc6J7Olea5XGmeS459LDdYin3al2QO5LDODHv+w9avYhpHJPqY/8SkNJ/YRvKdqzujXX3ZootXiEYRoaszb/EfL80INyiHcrN5Wol9Es3lcQYm/e5uH9XTSEVQ74Uy2dWVUUWXMDGKXeQix7Os1k1ZrZvSyLmbB6+cwLIAACAASURBVK1fs97dABcm2pi2coDKQX1/8Lrl+ri10JMy4mZLcZTzTPcpgM8lWAOKzmoVm3Q97FhZkjmQsx2vsEvX9HqLBU+U+6jG+0UX8X+WH7jH+a8gf/7Qz3ex+Q/aOcYYXj+oK5OnG4S178bj9ePQFjo73qWF2sZi3cp/vY9jJNnqAJ/ZnmOPrhp2P8Ba3Zi1urGhuihQgB3QVcixf87ajJsoxEI3x1vcbZnIXZbixdgrzqsM35EIysvQbAGylFJOoBKwDXgU6Om9PgaYhQiFqLxofS/oPFBIBKcz0MzNGBQkIKbZBrNUt+Bl59VsJXybnZfZn19cJ3Of05OFMkMV0ZDdfj13Bk6+zHgq6J47LeE7iECSEWzjsynUU/u53TKF2y1Tgv7oOpmiq5csyh31OsAD1m/KNshScJV5Tlz97yocxCEqsS4g/UMgDznv4g3bm0Ft893tON0UXD9gqbsFi3UrTrJ/wDIDDyyAFTrHf/y660ped10JeBYiNopwYQ7qm2Mfy+KM26muPK67M92nMMfdgQmus3jY8iWmsN+BZ8IPVD8F/k4dAWrIQJ4v6sdPrtOCBEJL+6coNOsyb+Jvd13ucd7PPQammHxdnWx1wB8NvlPXoJ7aH9TnKscwtuvaHKJSkEAAWK2bsk672K5r8bTzhqBrpbMZKFo7it2N/1t0HZeYfqeJKZ9N7mxecyVPKKRcfaS13gq8CGwCtgMHtNbTgHpa6+3ePtuBukb3K6UGKqVylVK5+fnR9dzHGrU5wIaM6+lcykIfgUbXwFD880x/BQkEgDamrVxlnsOvmYOoxmHDTIznmJf4I3ABPg1IfrYk8//Cxx8QjKQoebJNBKGTWihHdcWpo/2889qkPXsf1SiKsMbLsY9lm64NwCp3Ex51DgDgJ9epdLK/x+POW/3qmpnuTgAcplKQOgegi/1t2tk/jjgGjSnihN3R8QEvOa/mAocnmK4ICwt1a65zPs61haU3SLe1j/aPyYmF+bp90HUXZoqwkGMfyzmFxkkAAf8u1rcz7uHw9L3Y8Yy/zwLdlm3UifgMF2a6O95ksrtb6T5MCVRTBQDcHeC5lwxSLhS8toLLgeZAQ6CyUuqG6HcVo7UepbXurLXunJ2dGENSeXK2aQl5mf05Ta3mLNNSTErzoKXYY6et2kR303LyMvvzsGVclCdBb1Nx3ppKAavy+y3RV7ozMx7yZ2J8yfo2gZ5ElgChUFIag0APkDkZ90ftmwo6q1VkqXADeCqZ6zrRf/y26/JSP8euraW6z7dK9eUS2qlr8oXrXO4ovJ+PXBeyn6p85jqfqwuHk2Mfy2pdHEwXOMH/4OpKPjXKlAbkDdeVrNFNSn2/EQ5sCUlNctgbpe4LKnRgI8c+NqIaqjzw7bQSEwsfmfIwNJ8HbNRa52utncC3wBnATqVUAwDvz7SoEfipbSQA32T8h15mT56XMwJyq/yYMcQf6HS3ZVLE57RSW4Ly6ATuFLbrWlHHELjCv8o8l7zM6/3n7aP40YdSRRUndwvdmaSSTsrjwvl1xgj/d1de3OD0eKA4tUelMtnVtVTPCdSBt7R/yiWOp6P0Boe28knR+f7zpbo5zzqv40HnXYDiR3fXIDVPJN4vugiAN5Lk6VJR+Ft7jNOJSj+STGJ1wy4t5SEUNgHdlFKVlFIK6A2sBCYBPh+zm4GJ5TC2lFCHA+Rl9meA+Yeg9ivKkPUwMP89BAuFs4JyuMfH6Djyz8QT2ZxMJmQ86U8VHSu/uE4u9fu+dxmrC/5ye/TOvRwv0c3h0ef7VuwA37jODrtnsbtFWNuTXtfL9vaP6Gp/CxdmlukWXOh4LqzvhY7nuNTxNG0dY3iy6NaAK4pRrkvZQ3xpEp4r6s+FjudYqZvFdd+xxqPO/+Mp5w387m5fcudy4lrHEzi1manuLkl9T3nYFOYDXwN/AUu9YxgFjATOV0qtBc73nh/T+FId+OIGfPhysT9h/Szq/R9YI0/Ivlz5RhzSWf50yQBZqvxKi852dQhrK43hzedm6OPewvui9h/pzXEfKzc7hzDPdQJfFPXiRPuHzHN5/N7vKywu93iW4zUmuM4Iuu8ZZ3/udf6LHPtYejiKXV/7FT7OLYUeQb1RN/BPxq8WFRsIN7jDvVwyCLeC+tauR8lkF8We2it1My5zPBXkR79SN2OpDhcspcWN6bgWCBc7nmGwcyCHqMSHrotIvnKm9MzX7b3G5+SOsVziFLTWw7TW7bTWJ2mtb9RaO7TWe7TWvbXWrb0/K3b17Bjw5Zn3xQ3Ew33mbw1z29tw0kFt4AHL+Ij3Hooji2eyWRZBJ7s+ZEL0+dFf7HiG7vY3WORu6b+21t2InoWvcKr9XX/b9+7uUd9bqxTFzfs7H+fRov+jgCwGOP9Nb8cLfOcuFgL5ujr3O4NrAu8MUM1t0sWC63f3CRwkPChusy72n3jHdVnYDuVPd9uwe+qryH8KS3RL1utGUT6VEI3lujnjXT3LexgVColoTgF2baUSdvIy+3O2QQCXEQ8FpIcI5BvbML7LeJz+UYp6NIwyiaSaOe7gnYJvxR9qtH6z6Aq/YW87tbmi8Cl/RKjPx34v1fjWdRbfuM4q8b1ug//aQ5zGLpY/GOj5j5Lpn2ynuDzbdYdX9XO5ozjY7SCVgu5rb/8ozGsn0rjcmLjF+XDQ+4cX3cy5jheZ7erAErdHoPo8hwQhFUhCvCRgxkWDgIk5UzkZ7S1h6DMsl5ZsVfa0FalkX0ggT89Cj4ol190mqATiohC/b4Air3E2MPDqQefdMb23htd9z8dQ5wDGuc7FShFPWUf722NRZQ1y3suTzsP4tu2LdSua2z+jjdoS5K0DHmESDxoTdzvvp7rzMC5MuDCzQTfkJuejPGt5n5NNG2MyCAtCopCdAp7UDXmZ/cucn/9Elcd3tqGsz7yRuRnBvsRdTavL9GwftYlfLZJM7in8FwVRYgFW6aZ+Q+lpAakCOofkNZrjDjf0FiVwMhzr6g3Ap64L/G0+z5qSKMRKPsFZVzSmMIEQK2c5XqWjfVRQ2wGqcDhk1+FTXRnl9RGEZCFCAbjQ9AdAqfPz1+AQ71tfZHLG0KBiKsnAGpB2OV5y7GPJsSe2II6VIi5wPB+1zyeuPuTYxwZ5vtxVWCw0I63WnYTvFALpFZCj5gT7R0xznRbWJ89dj8edtwa1tbN/TGf7OzxTFHN4TELZoutywMDeEIovd85Gg7QLgpAsRCgQPad9JKwUUQOPf/+izDs43/xXooeVJIo9F3y670Id+4p8m65FX0exCsyiXGwlmxHOG8P6fu+KnBQtloRpvgjdSEJho27AU87r+a+zH0fIDMqe6qNn4St85jo/qM1Ohj+XjSAIwYhQAOa6w90mi9EY1Qp42/oaizLvIJt9SRsXUGL6XfBkjBxf1CPuZ/uiNts4PuUJ5y287Lza0IUUPNkjc+xjOcPxJqt0U/Z5003/6joJgI9cF4alGL63jOH4xTuFyHzouph3XJcZXjPy4xcEIToiFPAkv4rEV7YRQRG+Pnx5+f/MvKdU73zaGf5MH4EpDbboyLlWAG4ofBRQDC66M2b//03ubL4N8eD51HUBr7uu5D6nsf//DHewauZx520UajN7A4rar9eNWOuO3T3yfMfzXOkYHvF6UQnqo1ACU0oAx7V/vSAkC/E+ojgJlhFGBuJqCciv/4HrYsa7zqGV2spG3YC/IlTs2qzr8U/HEzxkHW+Y/G2eO3gi7GgfxeLM8PzuLwXkJYqWZ/4AVRjhvJFqqoD7Ld8CcKlBSoXJ7m5MdoRH8l5ROIJrzbP4OCDXfSTW6sZRr/tSDsQqFG5wDqV10Vamh0R3C4IQO7JTIHjS+cj6vD93TiADzJ4UDk3VTpYYTLqxMN/tSQXsy0lzgCos0G3ZSzV/n672t8Lyr/yh20fMBhrqjx/JgPmGN71xLHzkupBXi67mWed1LHc3Y2kcScEKyOIj14VhdZBLg09YG8UcGKNKFDSCIERHdgqAKUAonGteREu1LSzNbmVvLqHAIu/xMNQ5wO8WGY1d1OR+5908bx3FJYXFydyuK3wsLLnbOIMygOApD7hcN+NHVxfmZ95r2CcWRrkuZZTr0lLfX1a26dqsczdkeNHNJXcOYGxRL8wx7i4EQQhGhALh6oksVUgGhUGFapZ488kEBj7FwwzXKVGv93C84s9786O7Kz86gqNsfwtREwHMc59k+KzA8oBn2F8v9/TRpcWBjfMKX4z7vqFF4bUeBEGIjbQXCmt3HgraKQBk4mC87T+cbNrobxttez5mQ+4hnUVVbxrpSx1Ps043LDHSNTBvTiQ2uOvTwrTDfx7LWngbdWLrKAiCgNgUmLjxyzChYEIHCYR46eD4kG72N3jJeTVLdfO4Ux9EwqdGecx5GwALdeuEPFcQBMFHzDsFpVQW0FRrnZh8DRWEKZvGcxKnBrUF1zcuZpbtgRKf969Cj4vqDmrHZdyNhdnujv7dyueu8xL6bEEQBIhxp6CUuhRYBEz1nndSSkUuA3YMobU7bKcQqZh7jmlnic+b5D4zIeMSBEEoD2JVHw0HuoKnsovWehGQk5whpRY3OkwolIatkt5YEITjgFjVR0Va6wOe6pnHFwpQqvRCYb67HdcWPpm4AQmCcEzR//SmjJ1ftgzLpcFmTo5JOFahsEwp1R8wK6VaA/8CSl9QuAKh0TFHzPpY5G7BONe5/OQ6LSjNgyAI6cez/+hQLkJh9sO9kvLcWEXNfcCJgAMYCxwA7k/KiFLM3oLCuNVH+boG41znspvqcUTbCkLyaF6ncnkPoUy0qltyKnEhmPrVE+PVGEqJM5pSygxM0lo/prXu4v33uNbanpQRpRiXW2OKkvvIiGMnTbaQLtSpYivvIZSJp68wDsSMlQYGE2SXnJoGPZNPpyY1qJpRrIRpUy8+gXdHjxaJHlJclCgUtNYu4IhS6rhNQJ8IQ7MglCcqaoLxxOwk+pxYcoClzeKZUk5qVK2EnsGYSrBXTrr3TPqeWN9/Pu2B4lTxg/u0pUV2+Oe75YzoObuGXtSOh/u2jXmMjWpkxdTv9Ba1glQ70x44J+Z3AHRvWbvE7699g/i+33iIVfdhB5YqpT5USr3u+5e0UaUUFdWmsEdX5WT7+3Syv5fCMQlCYvnw5s5lfsZr/U7h7etPZeI9Z3LnOS1pVz/cnnand5XbrFbi1Fn/OKURJzeuQbWswNV3VUbdeBrf3NWde3qF1/cGyLJFn96a1qrEnT1a8tODkSftz28PLgb1x2PG+cuu6NTQfzz4grbUrBx95/bL4J4Rr/VsW5ev7ujO3Ed6kTfyYsM+j17YLurzy0KsQmEy8AQwG1gQ8O+4IJpQ6O54k4NUZr8YlNOKsqozKhotsqswJ4phsmfb7BKfkWk1c1GHBnRsUoMhF7Zj6v2RCzu1qVeVZ/8RrXhVMVMGnR31et+TPDuEf/cJXtVfcGJ9TmtWK6itVsBk3KttXf9xh0bGig6TSdGqbhUeOr+Nv+2N606hepanpkmmNbgqYd2qmSwedgHf3Rtcj2REwP8XSwxeQc1qGwtNs8mzY6pks9C4ZiXDPnee05IebUr+fZWWmISC1noM8AXFwmCst61UKKVqKKW+VkqtUkqtVEp1V0rVUkpNV0qt9f5MiUJQmY4woc3PzMkK10kOcd5OIdaw9h26fHSVQuo4rZnx7/iN66InNkwWT11+ImNvL7mEqRFntvLE0DSpVYnFwy7wt99yRo7/+Nx2dUNv81PJFrlc64R7zvSvpj++pQvXdm1K8zqV+WeXxlwWsHoOJFDXf0KDarRvUC3qO4rHUbKz5Ev/7Og/DnShP7mxkVAovn5f7+KUMZd2bBigjgpfMFbPstKhcXXGDezmFw7VMsPnCSNWPdWXRU96Uud/dUf3oGuT7j0z6PcTymv9OtHnxHoMSeIuAWKPaO4JrAXeAt4G1iil4q//WMxrwFStdTugI7ASGALM0Fq3BmZ4z5OOMntSWtxdP/yPwq6Dt4A3FnqGFFgwXjg+aV6nMoufDP4Dzaldyb9qDaRu1YywtsXDLmDVU33p1qIWwy49oUxjMZsUN3bP4YxWkavw1Yqirrj05OLJ2bcC9uHTTXdsHLn64LQHevDxrV0Mr3VqUoMzW9Uhb+TF9GpXl0Y1spj57540qJ5FlQwL55/gsUO8cm1HVozow5LhFzD+zjP8K3PfyvikRtWpU8XGI33DJzzf1F3JGllw+OwNrbKNjbrxWg2NLByhZo9uLWrTwVDYRCbTaqZGpeDfVedmNVn05Pmc3LgGVTIiC77Tm9fmvRvLrgYsiVjjFF4CLvDlPVJKtcGzczgt6l0GKKWqAT2AWwC01oVAoVLqcqCnt9sYYBbwSLzPTyQ25Qw6n+M+OeZMqcKxy1mt6pBpNYepDu420F2f3rwWg85rTf/35/vb7u3Vyj/5jhvYndy8vWUaz5cDiyvcrX3mQgocRfyyJp9B4xb52/ucVI/e7esy+OslYfdf07lJxGd/d++ZuLQmwxJ5wm1cs1JEVUasVLJZglb6Pdpk89L0NUETbe7jnhX0f6d6CkoNOKs5H87d6J9ETSbF+mcvwukK9xa8oVszrjqtMZVsFl7+Z0c27i7wXwvU9z92UXv+zNvLtBXRU9Y0r1OFvzbtp0qGlQ9u6sztn+TGtJsJZMI9Z1I1s+QpVinCBIURyXJBDSVWm4I1MBGe1noNGOhVYqMFkA98rJRaqJT6QClVGaintd7uff52wHA/q5QaqJTKVUrl5ufnl3IIsbHWLVW80pFMq/GfhdUcvn68q2fLMNXBQxe0CTrv1KQG/+xc+v9LnXOK9eZWs4kalWxc3im4FrZCRZz8I/n11K2WgcVsiioQyopPDVM7ZCfTpJZHyFzbJbLAerhvWz64qTNdmxd/frNJhQlr8KiKfELnylMb89AFHvvD+mcv4pVrO/n7ZcY4sT99xUl8fEsX2tavSktvDEWHRpF3U0Z0alKDlhF2LgCnNq3BNac15sVrOkbsUx7EulPIVUp9CHzqPb+e0huaLcCpwH1a6/lKqdeIQ1WktR4FjALo3Llz0nxJO9vfYTfHrRduudO9RW1+27Cn1Pc3qpHF1v1HY+7fu11dZqzaFfH6a/06Ba28jSjJbdJHaDoYi9nE81d35OrTmvDP936L6RmxcHmnhkxctM37TuM+repWwWQKvtiuflVW7TjE2a2MjZXXdm5C7So2GtXMon61sq1O/31BW85ulR0k2MCj7orkWTP1/rOpnmUlw2LmvBNKdoONhk89FfgNtK1flWkrdpJtoPbzkWUz08trZ2lepzJjbz+dUyPYmUqLxWzihQomECD2ncJdwHI86S0GASsA40rzJbMF2KK19u23v8YjJHYqpRoAeH9G/gtOMmOLzhWBkCSu69qEXwb3xGKw6i6JJrWK/cT/e9XJcd17VuvI+vhQ+p/e1LD9og4NSrz3tX6dIl4LXPFCscE1w1L8Z3hpR2PjrBF39GjpP24Yow894FdpRBIkbetX5eG+7bj+9Gb0bl+2SdlqNsX13QO0q1+NBtVj/zzxMqh3a8bf2T2iM4ERZ3hViqVl3pBzo7qhViRiFQoW4DWt9ZVa638ArwOl+oa01juAzUopn39ZbzxCZhLgK8Z7MzCxNM9PBK8UXVVerz7uqV8ti2a1KzPgrOiBRUZ8NqDY+ybeicZiUjx/1cm8e8OpnBPBnS9v5MXkjbyYc9sZT4RWA1dDpRQ6YL8aqtYJ5a3+xbU7xt95Bk9ccgLf3XdWWL+WBsFYoZzQsBobnr2IifecSZeQlbiPf/UOL8T0xnWn8sB5bTixoXEA1PEeymkxmyJ+X8miYY2siG6oFY1Y1UczgPOAw97zLGAacEYp33sf8LlSygZsAG7FI6C+UkoNADYB15Ty2WVGIpwTRyWbmSOFrrD2ngE+5A2qZ7L9QPSsKbUr28r0R9WybhXOaOkRJLNWJ84WFe9+5+KTG3BPgK+CTzg+emE7Ppv/t38VP7hPO6xmRVYJq1OTSdGxSbiuu0YlK4/0bcdlBjuP+tUzGXReelXtq+L9XjMtx16usuu6NmXLviMpe1+sQiFTa+0TCGitDyulSu2O4K3HYORbZRwumCIudTzNQMv37ETiEBLB+mcv4tkfVvLh3OLSptpA4A65sF2QPr9V3Spc17Up63Yd4os/NidkLD6BAHDzGTl8v2Q7hx1F/rYzo7h7poI7zmnJHee05LCjiGa1KnHBCfXCbAGx0KlJDS45uQG3n12++XMqGg+c14aalWxceeqx5zzy3JWxBQEmiljFZoFSyr/vVUp1BmK38h0jLNc53Of8F/Gv/yomkbxoUsGb/U/BbFJc19VYPx9Im3rB0eIKzwo60Pc+FhvvDd2K32UxKVaO6GvYr32Daiz7T5+g+II6VYyNjgsej172tHJGYj13qmRYuOOclqUSCOBxgyyrQLjk5JJtJ8camVYzd57T0m94joRka419p3A/MF4ptQ2PyrEhcG3SRlVOuI9BYXDlKY34duFWw2uVbBbsTuN608miS05N/szbR7Z3kg2dzENdE4GIKpKSkryF8vQVHfjs9+K89lk2M38+dl7EiaBzTk1+WLoj6jNrV8mgW4ta/L7BE2tgDvlApzatSaGB3/yxyPL/9MGkFFlx+uMfLywdfoGh3SjdiPoNKKW6KKXqa63/BNoBXwJFeGo1b4x277FJxRMKY27rGvX6iQE5XT4d0JURl5/oPy8pZe85bbLpFKKP7m2Q7uCB89qEtUXi6Ss6cE6bbEM9d9t6Vel/erOw9pw6lZnzcC+GeyN/ffNu4Pz77g2xxUku+0+foPPsqhlRo31j4dMBp/t3HSaTYnnAO5RSZFjMrHqqL2ufuTCm5305sBuz/t2zTGNKBpUzLGkrEACqZlrL5GFUUX+v8VKSWHwP8C01uwND8aS62Ic3VkBILINDkn5VLuGPNFCMnd06OyhYJnSlPW5gt6B8N2Nu6xqWgvdJg5QMRtkm1z97EV/d0T0sZXHb+lUZc1vXsD+uxjWzmHr/2RFX7U1qVeIfp3j0vf26BKucHjivjd/P/aIO4WkmAsmIw5AYaypkq9kUNFlWNkhFkGk1x7zKPL1FbXKO8aI4QjjHy++1JPWRWWvti9G/Fhiltf4G+EYpFT3Sp4Kj3RaUqajkjglk5JUdmLhoW9SgrbKWwQ5cFb/4z46cOfJn/3m3FrXp1qI2o+fl+duGXXoCF55Un4Y1Mhk7fzNNa4X7DxgFbZlNiq7Na9GoRhYb8j0pBc42cBP13ZllNYcFdYVSvZI1KKDJN5ZGNYsn77evjzuzSkSu69qU9+dsNPzMgpCulCgUlFIWrXURHs+ggXHcK4TQr2tT+nVtSs6QyTH1j5YcKxKBK/9GNbLo2TY7qgtmptXsT8NrtEuIlU9u62qYzrd5ncrceU5LrusaOZ1BJK4+rTENa2RxRsvapR5XNKp601OEqtAEIZ0pab/7BfCLUmoiHm+jOQBKqVZ46jQLMfJ8jBG4gSqfsxLgJqkTEHKhlOLjW4yzZPqya9atZuy9o5RiyIXtShVjoJTizFZ1StxhlJbsqhl8f99ZPH91fNHRgnA8E1UoaK2fAR4CRgNnae2fYkx4AtCOaZwHilMSVHIn3oPk3l6tqFnJsxptHJCiwahilQ+LSfmjUG85M6fMYyjNbiMUBfRqV5fZgz1FWmwBuvMHzm/DlEFn065+8soDJpOTGlUvk3FREI43SpwxtNa/G7StSc5wUovbWZ2j264iq+E3NHC6iJ5MN3Ya1cjisk4N+XeftuT+vdfvzuhj6v09+PLPTTzyzVLAE9FbWORmT0EhretVoWfbujzozTe/dEv8G7If7+/Byu0HAfjP5Scyeel2LAEG3vduPC1qMrBQ+nhrCPiMrYFlEc0mVep6sZ2a1CCndmL1+T77R58ToxukBUEwJu3tAkUHutC4xhSqqP0Je+avQ871H2dX9WSZDF2NXtulKVee2pgx8/K4qXsOA8b8yZy1u8NUJYEFvM9tV5efvZk+T29ei/kbPcLmvPb1+GllsUhrW78qbb27EV9a58DHxjth+rx0iqORE6POmXDPmQl5zk8P9mDtTk/AvdmkmD+0NzUqlTazuyCkN2kvFMAzxekETHRG6Zyf/cdJnNWqNqcYGDOtZlOJ0aeBQuKjW7r4jdTtG1TzC4W3rz+VAoexJ5XV7PES+r84olyn3n82uw8VcsOH84MvaN+YYn5USmhVtyqt6har5OqVMd2zIKQzIhS86DgnuoE9WjBq9oagtm/vPoNlW4PVPVUzrVzbpeRUD/Him/hqV7Fhs5iwWYwDtJRSYbVgS6Jd/WpQ32M7CIzWlTSBxZhNCpdbvhHh+EOEAr6dQuyc0rQGQy9qz5C+7Sh0uWn3xFTAM1GXdpX61OUn8ewPKzm9efSUvv/q3ZqW2ZW5uEMDGtfMSmqempmDe7Jlb3h2xgq2USgXZj/ci637jrv0X4IgQgHiVx/5ooZNJkWmKTGeKzl1KjPqppKLcvsM0BBfQZbS0KhGVlDUb92qGdxyRk7UEorpQuh3IwjHCyIUAKXj2ymEio+uzWuxo4R6AGVhwj1nMndtcutRx4JSiuGXnVhyxxQx5+Fex00yOkGoKIhQwDPJx5MhNSMkJXW8Ovt46dSkhkTdGtBE0lMIQsKRPLGAMiz9EplH+rZL2lgEQRDKExEKxG9o9uXMEQRBON5IY6FQLAYU8bukCoIgHI+ksVAAn8k4kvfRBSfUA+Cd609NeDoGQRCEikiaCwUPkdRHr/U7hReuPpm+J9VnljcZnCAIwvGMeB8BJq1xGrRn2cxc07nYJ3/E5Sdy8KhRT0EQhOMDEQrEbmi+qXtOkkciCIJQvpSb+kgpZVZKLVRKfe89r6WUmq6UWuv9WTNlYyExCfEEQRCOdcrTpjAIWBlwPgSYobVuDczwnqcEBbhFJgiC7/6jEgAAFK9JREFUIJSPUFBKNQYuBj4IaL4cGOM9HgNckarxmOIMXhMEQTheKa+dwqvAw0Bg4pp6WuvtAN6fdVM1mHhzHwmCIByvpFwoKKUuAXZprReU8v6BSqlcpVRufn5iksSZEJuCIAgClM9O4UzgMqVUHjAOOFcp9RmwUynVAMD7c5fRzVrrUVrrzlrrztnZ2WUaSE11iA5qAw3U3rCdgiSgEwQhHUm5UNBaP6q1bqy1zgH6AT9rrW8AJgE3e7vdDExM9liuM//MdxmPowCrCo4/SFT9YEEQhGOJihTRPBI4Xym1Fjjfe54SPKmzBUEQhHINXtNazwJmeY/3AL1T9W6LcvmPTVpsCoIgCFCxdgopxRSUJVVcUgVBECBNhYLWwSIgNHX2lac0Su2ABEEQKghpKRRCMRFsU3j52k7lNRRBEIRyJS2FQshGIe7Ka4IgCMcraSkUIFgISESzIAiCh7QUCqECQKFxi/eRIAhCetZTCDU0m4C9VOXWM3PIsprLZ1CCIAgVgPQUChC0L1CAC8WwS08spxEJgiBUDNJSfQTBwWqfFZ2PWBUEQRDSVChor2F5j65Ojn0sGoVSIhQEQRDSUij4KI5NEKdUQRAESFOhoL3KI7f/44tQEARBgHQVCt753++GqsUdVRAEAdJUKPgIyowqNgVBEIT0FgrF6iNPQU5BEIR0Jy2FQpj6yNNaLmMRBEGoSKSlUPDhEwpai6FZEAQB0lQo+ErqFNsUFJL6SBAEIU2FggcdLBRkpyAIgpCeQiHcpiBCQRAEAdJVKPiPlL9B0lwIgiCkq1DwbhWCdwrhKbUFQRDSjbQUCrNW54e0eIWCqJAEQUhz0lIoHLIXeQ607BQEQRACSblQUEo1UUrNVEqtVEotV0oN8rbXUkpNV0qt9f6smawxuLXPJdWL3/DsNuwvCIKQLpTHTqEIeEhr3R7oBtyjlDoBGALM0Fq3BmZ4z5NC+I7A+zXIRkEQhDQn5UJBa71da/2X9/gQsBJoBFwOjPF2GwNckawxbD9g9x4FR6zJTkEQhHSnXG0KSqkc4BRgPlBPa70dPIIDqBvhnoFKqVylVG5+fqjBODYOHHWGPhXve0v1PEEQhOOFchMKSqkqwDfA/Vrrg7Hep7UepbXurLXunJ2dXap365CfPoOzW8tOQRCE9KZchIJSyopHIHyutf7W27xTKdXAe70BsCtZ7w/dEGhxSRUEQQDKx/tIAR8CK7XWLwdcmgTc7D2+GZiYrDE0rpkFhCTEQ9RHgiAIlnJ455nAjcBSpdQib9tQYCTwlVJqALAJuCZZA6hV2WbYLoZmQRDSnZQLBa31XCInqu6dijFkV8kIbtCyUxAEQYA0jWi2WUI/tggFQRAESFOh4CM0W6oYmgVBSHfSWigQYmgWl1RBENKdtBQKYfsBLTsFQRAESFOh4CNUBIhNQRCEdCethUIxslMQBEGANBUKxTsCsSkIgiAEkp5CIeRncbEdQRCE9CYthUIoPuEgOwVBENKd9BQK2vcjJPeR2BQEQUhz0lIohE/+YlMQBEGAdBUKYb6okuZCEAQB0lQohCPqI0EQBEhToaD9NgUfoj4SBEGANBUKeXsKvEdiaBYEQQgkLYXCim2ektA+EdCxcXXPudayWxAEIa1JS6EQysAerQB4bv5zdPykI5sPbi7nEQmCIJQPIhQA5VUfzd8xH4D/rftfeQ5HEASh3EhLoXBW6zpAcfCaSQV/DVM2Tkn5mARBECoCaSkU6lXLDDpXISWj9zn2pXI4giAIFYa0FApVMixAsaFZqWChUOAsoMOYDhxxHknxyARBEMqXtBQKZlOwEAjdKfi47cfbALjv5/sYt2pc0sclJIYxy8fw7Pxny3sYgnBMkpZCwaSC4xNCbQo+lu9ZTv/J/Zm1eRbPzH+GT5Z/wvg141M0yrLh1m6+W/8dLrervIdSao4WHeWO6Xewau+qmPprrflg6Qe8mPsiX6z6IsmjE4TjkwonFJRSfZVSq5VS65RSQ5LxDlPIp3a4HBH7Lt291H/8Qu4LjPhtRInP11qzo2BHqccXL1pr3lj4BrdMvcWfv+mjZR8xdO5QOn3aiQ5jOviFg9Pt5KXcl9hv31/q9+237+eA40Dc9206uCno3OlyRs039eeOP5m3bR7D5g2L+txDhYeYunEqPb/qyWt/veZv/3DphwBhgnHAjwM4/fPTDZ91xHkk6mcrdBUyc9NMnG5nxD6r9q6i7zd9+fvg31HHLQgVEUt5DyAQpZQZeAs4H9gC/KmUmqS1XpHI95iVL4LZw35HfBPkol2LMCkTOwp2kF0pm0qWSrSt1ZbdR3czfs143l70NgCfXPgJla2VuWrSVQB0a9ANkzJxb6d76ZDdIeiZbu3GpEwccR5h+Lzh3HTiTbSs0ZKDjoOc9/V5tK/Vnt5Ne+PSLmZtnoXT7cRqsjK4y2CGzRvG5kOe2Iolu5fQMbtj0OQI0OnTTuTekEvnzzoDMHr5aABuPuFm+rXrR+OqjTlceJgJ6ybw8fKP2XVkF6/2epVXF7zKec3OY+vhrTxw6gM43U4u/t/FAPyzzT8Z3GUwXT7vAsAN7W/gs5Wf0a1BN37f/jsA/+78b444j/D2Ys93cnajs7ntpNuonVWbyyZcBsDcfnPZeWQnNTJqADD4l8H8tesvTs4+GQATJorcRYxZPoaPln1E94bd6ZvTl6W7l/LL5l9QSrFu/7qw39Orf73Kq3+96n9v//b96VK/C3/s+MPz+9capRRaaw47D7No1yLeWfwOu47s4qdrfjL83X+95mue++M5//nw7sO5svWVvL7wdc5oeAZd6ndh4rqJbD28lZmbZnLLSbf4/880rNIQq8lKjy978GrPV2lXux15B/I4s9GZgGdxYlEWNhzYQK3MWtTOqg14hPDuo7tpVbOV4ZgADjgOkGXJwma2ReyTalbvXU3jqo2pbK0c1L776G6W5C+hV5NerN63mirWKjSu2tjwGb6/C/DsHLt+3pUHT3uQW0+6Naif1prF+YupX7k+VW1V+X7995zX7Dyq2qpiM9tYsHMB2VnZNK3W1H/PXvteqtqqYjVZAdh8cDNHio7QtlbboGdvPrSZ6ydfzyu9XuG0eqdF/LyHCw+z88hOWtZoCUD+kXyOFh1l3rZ5vLzgZawmK+MuGUeBs4DGVRpTxVaFo0VH2WvfS/1K9dl0aBPNqzdnr30vP/39E1e1vgqzyRzjt504VEXKDKqU6g4M11r38Z4/CqC1fs6of+fOnXVubm7c71m99geunvcIp+yty+ydD/LUTXt5/s/nAWhZvSXrD6yP+5nVbNU4WHgw5v6NqzSmSBfh1m7Myszuo7upV6keWw5vifvdoeRUyyHvYF5c91SxVuGw83CZ332s0axaM7Yf3k6huzCovWnVpv7JIpCS/m/UyqzFXvte/3njKo1xuBzkH82PeI/vXaHPbli5IWaT2S/wc6rlYFbhk4RGs+HABn8f8EymGo3WOuinr92t3diL7NjMNhQqKMWLb07w3ulv8/fRxSlhfM/2Hftwup0UuYsAz3fscrtwazdu3Ia76JbVW4a1HSk6Qv7RfBpWbhj2/YT233RoU8TdW/Pqzdl4YGPQfS7t8v+N+Np8z69fuT6VLcWCLPC9dbLqYFZmqvx/e3cbHFV1x3H8+9tswIQEkhAWYwIhGUFjCwhYwEEZ8KEirXbG6qhTqy/qOE7t03ScDpQ+6Atf2BfV6XSmtdPq2MGqU22VsVSMopY6LSAIFFEKCNEImqRgAjEBEk5f3LOXu0k2ogR37+z/M3Nnz5779P8nu3vuPXv33OKyQftJLzexdCLFieJPfC8P9VlTXlzO4eOHAUgqSf3Y+qzrX1J7CXd/6e5h95GNpE3OuYuGmpdXZwpALRD9OXErkHGeL+kO4A6AyZMn81mUjB7Lpf3lnDflBr62cCbXNdVSVlzG+JLxXFp7aXiU+vze55mVmkVvXy9P73qalW+tZHZqNq2HW2nracvY5vQJ01l/YH34RgBoqmqivaedjp6OjGWbqpporGgkqSRHjh9BiLaP25g4ZiJN45tobmmmvLickmQJM1MzWde6jt7+3kF5FKmIfpfZNXJuxbk0jGug61hX+OG0sG4hoxKj6DzWycYPNg7aTjKRZOaEmXQf72ZL+5ZP9besLqmmp6+H7uPdn7xwxBWTr+DFd4Oj8QXnLOC1/a8Bgz9UAZZMWUK/66e5pXlQ3H0n+pgzcQ6bPtwEwIp5K7hv/X0AzJwwk63tWzPWWTxpMS1dLRzoPsCY4jFMq5xGzZgadn+0m46eDurK6ug81snUyqlDftfUMK6BF999kZoxNRzoPgDA0oalrN67mtqyWhrGNXC0/yibP9zMlfVXUpQoIqkkz+55lunV0znYe5D3j7zPorpFtPW0seN/O8Ij0xOcoHJ0JS1dLZSPKmfGhBn0u37Kist4p/MdplZOzfr3PHLsCNWl1Uwqn0SCBCi4gCKhBEJICh/Tee06tItpldNOzvPfsUWvxkuvM1Q5XEaRdSPLrNm3hvqx9VSOriSRSFCkIhJK0HW0i7XvreWaxmt4tfVVKkZX0FjROCin/hP9pHpTpEpTADRWNNLc0syiukUUF2U22Ol5ADOqZ7CtYxvjzxpPqjRFXXkdezv30lTVlHFGcujoIaaMnRJuv7e/l4O9Bzm/8vyM7ae3nSpN0VTVhNCg/QOUFpfS3tPOvLPn0ef6SCaSdB/vzjggSJWmaPu4jVmpWVSXVFOSLGFP5x7mnT2PV1pfYf458+nt62Xd++tYPHlx1v93eltnQr6dKdwAXOWcu90//yYw1zn33aGW/6xnCsYYU8iGO1PIty+aW4FJked1wP4cxWKMMQUn3xqFjcBUSQ2SRgE3AatyHJMxxhSMvPpOwTnXJ+k7wBqgCHjYOfdmjsMyxpiCkVeNAoBzbjWwOtdxGGNMIcq37iNjjDE5ZI2CMcaYkDUKxhhjQtYoGGOMCeXVj9c+LUntwOmMOlYNdHziUvnL4s8tiz/34p5DruKvd85NGGpGrBuF0yXp9Wy/6osDiz+3LP7ci3sO+Ri/dR8ZY4wJWaNgjDEmVOiNwu9yHcBpsvhzy+LPvbjnkHfxF/R3CsYYYzIV+pmCMcaYCGsUjDHGhAqyUZC0RNJOSbslLctxLA9LapO0PVJXJalZ0i7/WBmZt9zHvVPSVZH6OZL+4+f9Sv72V5JGS3rS16+XNGWE458k6WVJb0l6U9L345SDpLMkbZC01cd/b5zij+y7SNIbkp6LW/yS9vn9bpH0etzi9/uokPSUpLf9e+HiuOUQcs4V1EQwJPceoBEYBWwFLshhPAuB2cD2SN0vgGW+vAy435cv8PGOBhp8HkV+3gbgYkDA34Grff23gd/68k3AkyMcfw0w25fLgf/6OGORg99XmS8XA+uB+XGJP5LHD4E/Ac/F8DW0D6geUBeb+P12HwVu9+VRQEXccghzOVMbztfJ/8HXRJ4vB5bnOKYpZDYKO4EaX64Bdg4VK8F9Jy72y7wdqb8ZeCi6jC8nCX49qTOYy7PAlXHMASgFNhPcFzw28RPcofAl4DJONgpxin8fgxuFOMU/Ftg7cJtxyiE6FWL3US3wXuR5q6/LJxOdcwcA/GP6Dt3ZYq/15YH1Ges45/qATmD8mQjan9LOIjjajk0OvutlC9AGNDvnYhU/8CDwI+BEpC5O8TvgBUmbJN0Rw/gbgXbgEd+F93tJY2KWQ6gQGwUNUReX63KzxT5cTp9LvpLKgKeBHzjnuoZbNEs8OcvBOdfvnLuQ4Ih7rqQvDrN4XsUv6atAm3Nu06mukiWWXL6GFjjnZgNXA3dJWjjMsvkYf5KgC/g3zrlZQDdBd1E2+ZhDqBAbhVZgUuR5HbA/R7Fk86GkGgD/2Obrs8Xe6ssD6zPWkZQExgEHRzJYScUEDcJjzrm/xDEHAOfcR8ArwJIYxb8AuFbSPuAJ4DJJK2MUP865/f6xDfgrMDdO8fvtt/ozTICnCBqJOOUQKsRGYSMwVVKDpFEEX9qsynFMA60CbvPl2wj66dP1N/krERqAqcAGf2p6WNJ8f7XCrQPWSW/remCt8x2TI8Hv7w/AW865X8YtB0kTJFX4cglwBfB2XOJ3zi13ztU556YQvJbXOuduiUv8ksZIKk+XgS8D2+MSP4Bz7gPgPUnn+arLgR1xymFgQgU3AUsJrpLZA6zIcSyPAweA4wRHA98i6Ct8CdjlH6siy6/wce/EX5ng6y8ieDPtAX7NyV+rnwX8GdhNcGVD4wjHfwnBaew2YIuflsYlB2AG8IaPfzvwM18fi/gH5LKIk180xyJ+gv74rX56M/1+jEv8kX1fCLzuX0fPAJVxyyE92TAXxhhjQoXYfWSMMSYLaxSMMcaErFEwxhgTskbBGGNMyBoFY4wxIWsUjImQ1O9H60xPw46iK+lOSbeOwH73Sao+3e0Yc7rsklRjIiQdcc6V5WC/+4CLnHMdn/e+jYmyMwVjToE/kr9fwb0XNkg619ffI+luX/6epB2Stkl6wtdVSXrG1/1b0gxfP17SC34AtYeIjG0j6Ra/jy2SHpJUlIOUTYGyRsGYTCUDuo9ujMzrcs7NJfil6YNDrLsMmOWcmwHc6evuBd7wdT8G/ujrfw780wUDqK0CJgNIagJuJBgk7kKgH/jGyKZoTHbJXAdgTJ7p8R/GQ3k88vjAEPO3AY9JeoZgqAMIhgH5OoBzbq0/QxhHcHOl63z93yQd8stfDswBNvqbbpVwciA1Y844axSMOXUuSzntKwQf9tcCP5X0BYYf8niobQh41Dm3/HQCNeazsu4jY07djZHHf0VnSEoAk5xzLxPc8KYCKAP+ge/+kbQI6HDB/Sai9VcTDKAGwcBp10tK+XlVkurPYE7GZLAzBWMylfi7sKU975xLX5Y6WtJ6goOpmwesVwSs9F1DAh5wzn0k6R6CO3JtAz7m5PDH9wKPS9oMvAq8C+Cc2yHpJwR3IksQjJ57F9Ay0okaMxS7JNWYU2CXjJpCYd1HxhhjQnamYIwxJmRnCsYYY0LWKBhjjAlZo2CMMSZkjYIxxpiQNQrGGGNC/wfJMv8TLOtOWQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-5dfce1ce401a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet3_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-c4484100c63e>\u001b[0m in \u001b[0;36mnet3_main\u001b[1;34m(lr, g)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi_average\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_optimize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0moptimize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-62825d0c21bc>\u001b[0m in \u001b[0;36moptimize_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[1;31m#for param in policy_net.parameters():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m#    param.grad.data.clamp_(-1, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\roadmageb\\anaconda3\\envs\\d2l\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\roadmageb\\anaconda3\\envs\\d2l\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net3_main(0.00001, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS_END = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2_main('net_99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model('net_', 'net_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net1('net_49')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1r = 'net_7'\n",
    "net1 = DQN(45, 12)\n",
    "net1.load_state_dict(torch.load('./data/net4/' + net1r))\n",
    "net1.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht.reset_game()\n",
    "done = False\n",
    "while not done :\n",
    "    yacht.handled_roll()\n",
    "    state,reward,done,_ = yacht.get_yacht_output()\n",
    "    print(state)\n",
    "    print(net1(torch.tensor(state, dtype=torch.float, requires_grad = False).reshape(-1)))\n",
    "    action = net1(torch.tensor(state, dtype=torch.float, requires_grad = False).reshape(1, 45)).max(1)[1] + 31\n",
    "    reward = yacht.update(action)\n",
    "    print(str(action-30) + ' ' + str(reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht.reset_game()\n",
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacht.dice_status = [5, 5, 5, 5, 5]\n",
    "state,reward,done,_ = yacht.get_yacht_output()\n",
    "print(state)\n",
    "print(net1(torch.tensor(state, dtype=torch.float, requires_grad = False).reshape(-1)))\n",
    "action = net1(torch.tensor(state, dtype=torch.float, requires_grad = False).reshape(1, 45)).max(1)[1] + 31\n",
    "reward = yacht.update(action)\n",
    "print(str(action-30) + ' ' + str(reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy_net.state_dict(), './data/score_per_action_net/net1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
